{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02.semanticnetworks.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"12kSE0RVMyId8aqXitNI5j0iJxnX-6piM","authorship_tag":"ABX9TyPozP7Fs+34/91ISI4gIlJM"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","source":["#Imports"],"metadata":{"id":"3gNOVxdOLfr1"}},{"cell_type":"code","metadata":{"id":"VEr-dIfv90fP","executionInfo":{"status":"ok","timestamp":1641358964912,"user_tz":420,"elapsed":2565,"user":{"displayName":"Christopher Vargo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02946764354117096753"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7df6788c-6669-43e0-ee7c-4d8a4d4bf85c"},"source":["import glob\n","import os\n","import shutil\n","import json\n","import csv\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","try:\n","  import pyvis\n","  from pyvis.network import Network\n","except:\n","  !pip install pyvis\n","  import pyvis\n","  from pyvis import Network\n","from time import sleep\n","import nltk\n","wn = nltk.WordNetLemmatizer()\n","ps = nltk.PorterStemmer()\n","import re\n","import shutil\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","from nltk.stem import WordNetLemmatizer\n","wordnet_lemmatizer = WordNetLemmatizer()\n","import string\n","import itertools\n","punctuation = string.punctuation\n","stopwordsset = set(stopwords.words(\"english\"))\n","stopwordsset.add('rt')\n","stopwordsset.add(\"'s\")\n","from datetime import datetime"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"]}]},{"cell_type":"code","metadata":{"id":"o2iBARi-s-aX"},"source":["WORKING_DIR = \"/content/drive/MyDrive/MSDS_marketing_text_analytics/master_files/3_network_analysis\""],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!wget http://128.138.93.164/nikelululemonadidas_tweets.jsonl.gz -P /content/drive/MyDrive/MSDS_marketing_text_analytics/master_files/3_network_analysis"],"metadata":{"id":"VoZUyrxq0-c_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!gzip -d /content/drive/MyDrive/MSDS_marketing_text_analytics/master_files/3_network_analysis/nikelululemonadidas_tweets.jsonl.gz"],"metadata":{"id":"XePW56jB8QXU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Data Prep"],"metadata":{"id":"OgBGBHTBLl-j"}},{"cell_type":"code","metadata":{"id":"j1QDCkXKIzkw"},"source":["#Removing urls\n","def removeURL(text):\n","  result = re.sub(r\"http\\S+\", \"\", text)\n","  return result\n","\n","#Extracting contextual words from a sentence\n","# tokenizing is taking out all the words in a sentence and turning it into tokens/words\n","def tokenize(text):\n","  #lower case\n","  text = text.lower()\n","  #split into individual words\n","  words = word_tokenize(text)\n","  return words\n","\n","#stem - peaches : peach : reduce the number of repeated words\n","def stem(tokenizedtext):\n","  rootwords = []\n","  for aword in tokenizedtext:\n","    aword = ps.stem(aword)\n","    rootwords.append(aword)\n","  return rootwords\n","\n","#removes useless words such as a, an, the\n","def stopWords(tokenizedtext):\n","  goodwords = []\n","  for aword in tokenizedtext:\n","    if aword not in stopwordsset:\n","      goodwords.append(aword)\n","  return goodwords\n","\n","# feature reduction. taking words and getting their roots and graphing only the root words\n","def lemmatizer(tokenizedtext):\n","  lemmawords = []\n","  for aword in tokenizedtext:\n","    aword = wn.lemmatize(aword)\n","    lemmawords.append(aword)\n","  return lemmawords\n","\n","#inputs a list of tokens and returns a list of unpunctuated tokens/words\n","def removePunctuation(tokenizedtext):\n","  nopunctwords = []\n","  for aword in tokenizedtext:\n","    if aword not in punctuation:\n","      nopunctwords.append(aword)\n","  cleanedwords = []\n","  for aword in nopunctwords:\n","    aword = aword.translate(str.maketrans('', '', string.punctuation))\n","    cleanedwords.append(aword)\n","    \n","  return cleanedwords\n","\n","def removesinglewords(tokenizedtext):\n","  goodwords = []\n","  for a_feature in tokenizedtext:\n","    if len(a_feature) > 1:\n","      goodwords.append(a_feature)\n","  return goodwords"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["json_file = open('%s/nikelululemonadidas_tweets.jsonl' % WORKING_DIR, 'r')"],"metadata":{"id":"vQBfHnic15F-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["There's a lot of metadata in a tweet! If you want to take a look at all that you can get from a tweet:\n","https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/tweet"],"metadata":{"id":"iEbCsuo_8zom"}},{"cell_type":"code","source":["uniquewords = {}\n","\n","for i, atweet in enumerate(json_file):\n","    if i % 10000 == 0:\n","      print(i)\n","    tweetjson = json.loads(atweet)\n","    text = tweetjson['full_text']\n","    #natural language pre processing : clean the tweet \n","    nourlstext = removeURL(text)\n","    tokenizedtext = tokenize(nourlstext)\n","    nostopwordstext = stopWords(tokenizedtext)\n","    lemmatizedtext = lemmatizer(nostopwordstext)\n","    nopuncttext = removePunctuation(lemmatizedtext)\n","    \n","    # print(tokenizedtext)\n","    # print(nostopwordstext)\n","    # print(lemmatizedtext)\n","    # print(nopuncttext)\n","    # sleep(10)\n","\n","    for aword in nopuncttext:\n","        if aword in uniquewords:\n","            uniquewords[aword] += 1\n","        if aword not in uniquewords:\n","            uniquewords[aword] = 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mSrz-9ofjsKs","executionInfo":{"status":"ok","timestamp":1641359110327,"user_tz":420,"elapsed":97637,"user":{"displayName":"Christopher Vargo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02946764354117096753"}},"outputId":"a37a2861-9e49-4242-bc43-1e0ca4fbe4cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","10000\n","20000\n","30000\n","40000\n","50000\n","60000\n","70000\n","80000\n","90000\n","100000\n","110000\n","120000\n","130000\n","140000\n","150000\n","160000\n","170000\n"]}]},{"cell_type":"code","source":["len(uniquewords)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eIOWn78gn182","executionInfo":{"status":"ok","timestamp":1641359110328,"user_tz":420,"elapsed":8,"user":{"displayName":"Christopher Vargo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02946764354117096753"}},"outputId":"f3e89ffe-1ac3-4841-e70f-e36da6fdb1ff"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["98470"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["#  list of unique words: key - word; value = number of times the word appears.\n","wordstoinclude = set()\n","wordcount = 0\n","for aword in uniquewords:\n","    if uniquewords[aword] > 300: # play with this number to get around 1000 words\n","        wordcount += 1\n","        wordstoinclude.add(aword)"],"metadata":{"id":"mN2SV6G1n5yy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(wordcount)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HmRL97vJn7xr","executionInfo":{"status":"ok","timestamp":1641359168583,"user_tz":420,"elapsed":143,"user":{"displayName":"Christopher Vargo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02946764354117096753"}},"outputId":"f3869263-a8b1-4ed7-9c4a-953e5551a9e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["923\n"]}]},{"cell_type":"code","source":["json_file = open('%s/nikelululemonadidas_tweets.jsonl' % WORKING_DIR, 'r')"],"metadata":{"id":"OIWez2NNpSGD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Graph = nx.Graph()"],"metadata":{"id":"-9P4974Qo4D-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["uniquewords = {}\n","\n","for i, atweet in enumerate(json_file):\n","    if i % 10000 == 0:\n","      print(i)\n","    tweetjson = json.loads(atweet)\n","    text = tweetjson['full_text']\n","    #natural language pre processing : clean the tweet \n","    nourlstext = removeURL(text)\n","    tokenizedtext = tokenize(nourlstext)\n","    nostopwordstext = stopWords(tokenizedtext)\n","    lemmatizedtext = lemmatizer(nostopwordstext)\n","    nopuncttext = removePunctuation(lemmatizedtext)\n","    \n","    # print(tokenizedtext)\n","    # print(nostopwordstext)\n","    # print(lemmatizedtext)\n","    # print(nopuncttext)\n","    # sleep(10)\n","    \n","    goodwords = []\n","    for aword in nopuncttext:\n","        if aword in wordstoinclude:\n","            goodwords.append(aword.replace(',', ''))\n","\n","    allcombos = itertools.combinations(goodwords, 2) # set this to the number of words you want in each combination\n","    for acombo in allcombos:\n","        row = []\n","        for anode in acombo:\n","            row.append(anode)\n","        Graph.add_edge(row[0], row[1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bPuwXCTaoZ09","executionInfo":{"status":"ok","timestamp":1641359532955,"user_tz":420,"elapsed":110409,"user":{"displayName":"Christopher Vargo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02946764354117096753"}},"outputId":"f1b7482c-a962-47e7-9600-779e4ba22b99"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","10000\n","20000\n","30000\n","40000\n","50000\n","60000\n","70000\n","80000\n","90000\n","100000\n","110000\n","120000\n","130000\n","140000\n","150000\n","160000\n","170000\n"]}]},{"cell_type":"code","source":["nx.info(Graph)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"HCORIS0yb_S5","executionInfo":{"status":"ok","timestamp":1641359533500,"user_tz":420,"elapsed":8,"user":{"displayName":"Christopher Vargo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02946764354117096753"}},"outputId":"4615ae48-f9b5-4170-98af-0829fba6a7cb"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Graph with 923 nodes and 240694 edges'"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["fig, ax = plt.subplots(1, 1, figsize=(300, 300))\n","#ugh these settings are such a pain, but here's the way to look them up: \n","#https://networkx.org/documentation/stable/reference/generated/networkx.drawing.nx_pylab.draw_networkx.html\n","nx.draw_networkx(Graph, ax=ax, font_color=\"#FFFFFF\", font_size=20, node_size=30000, width=4, arrowsize=100)\n","plt.savefig(\"%s/semantic_network.png\" % WORKING_DIR, format=\"PNG\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zbhvxJFle9TU","executionInfo":{"status":"ok","timestamp":1641360396527,"user_tz":420,"elapsed":345351,"user":{"displayName":"Christopher Vargo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02946764354117096753"}},"outputId":"97569b61-d967-40d8-896f-80d63faf6980"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 8294 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 8294 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 8297 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 8297 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 128293 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 128293 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 128081 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 128081 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 128548 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 128548 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 129300 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 129300 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 128064 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 128064 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 129321 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 129321 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 128248 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 128248 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 128079 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 128079 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 128095 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 128095 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 128591 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 128591 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 129315 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 129315 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 127873 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 127873 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 127998 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 129392 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 127998 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 129392 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 128640 missing from current font.\n","  font.set_text(s, 0.0, flags=flags)\n","/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 128640 missing from current font.\n","  font.set_text(s, 0, flags=flags)\n"]}]},{"cell_type":"code","source":["plt.show()"],"metadata":{"id":"iSKbFijZrep-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nt = Network('1000', '600', directed=True, notebook=True, layout='force_atlas_2based')\n","# populates the nodes and edges data structures\n","nt.from_nx(Graph)\n","nt.show_buttons(filter_=['physics'])\n","#nt.show('nx.html')\n","from IPython.core.display import display, HTML\n","display(HTML('nx.html'))"],"metadata":{"id":"Nhdi-fDLQnDs"},"execution_count":null,"outputs":[]}]}