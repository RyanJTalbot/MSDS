{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "564ba54e-3f30-4ab6-ba22-64557cc30c62",
   "metadata": {},
   "source": [
    "# Online News Popularity Prediction\n",
    "\n",
    "**Dataset Source:** [Online News Popularity Dataset](https://www.kaggle.com/datasets/ishantjuyal/online-news-popularity)\n",
    "\n",
    "**Objective:**  \n",
    "Predict the number of shares an online news article will receive on social media platforms based on various features extracted from the article and its metadata.\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Problem Statement](#Problem-Statement)\n",
    "3. [Data Loading and Overview](#Data-Loading-and-Overview)\n",
    "4. [Exploratory Data Analysis (EDA)](#Exploratory-Data-Analysis-EDA)\n",
    "5. [Data Preprocessing](#Data-Preprocessing)\n",
    "6. [Feature Engineering](#Feature-Engineering)\n",
    "7. [Model Building and Training](#Model-Building-and-Training)\n",
    "8. [Model Evaluation](#Model-Evaluation)\n",
    "9. [Results and Discussion](#Results-and-Discussion)\n",
    "10. [Conclusion](#Conclusion)\n",
    "11. [References](#References)\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In the age of digital media, understanding and predicting the popularity of online news articles is crucial for content creators, marketers, and publishers. This notebook explores the Online News Popularity dataset to build models that predict the number of shares an article will receive on social media platforms. By leveraging various features such as textual content metrics, metadata, and sentiment analysis, we aim to identify key factors that influence article popularity.\n",
    "\n",
    "---\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    "This is a **regression** problem where the objective is to predict the continuous variable **'shares'**, representing the number of times an online news article is shared on social media platforms.\n",
    "\n",
    "---\n",
    "\n",
    "## Data Loading and Overview\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9751695e-0e24-4241-a7da-5a2ffe3045c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfb41bc-40f8-46bc-8c47-3de4ce94f906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For modeling\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# For warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# For SHAP\n",
    "import shap\n",
    "\n",
    "# Setting visual style\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d16251-4c5c-4cb9-9de0-d7c7f7958d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "df = pd.read_csv('OnlineNewsPopularity.csv')\n",
    "\n",
    "# Displaying the first five rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d7c54a-92c8-4a18-92e5-08602bae00fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying dataset shape\n",
    "print(f\"Dataset contains {df.shape[0]} rows and {df.shape[1]} columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5436ba8b-39e5-4c72-956a-5170ad1cfe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listing all columns\n",
    "df.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479a2eee-90c1-416c-9280-d7366cf8c1e7",
   "metadata": {},
   "source": [
    "Removing Leading and Trailing Whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7449fcc5-18f4-4e4f-9e6c-4bc5c7771ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing leading and trailing whitespaces from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Displaying cleaned column names\n",
    "print(\"\\nCleaned Column Names:\")\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5169b42-c16d-408f-8abf-3b1f83514432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping non-predictive columns\n",
    "df_clean = df.drop(['url', 'timedelta'], axis=1)\n",
    "\n",
    "# Verify the columns after cleaning and dropping\n",
    "print(\"\\nColumns after cleaning and dropping non-predictive features:\")\n",
    "print(df_clean.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7b5703-2445-4146-a896-1e33822eee6e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10066414-5018-4af5-9679-d8a22371f7a6",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "### 1. Understanding the Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5292fd65-7546-4b62-9ead-dc4ef581aad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of target variable\n",
    "print(\"Description of 'shares' variable:\")\n",
    "print(df['shares'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c713bf5b-1cb4-425d-ad8d-a343359530b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of 'shares'\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(df['shares'], bins=50, kde=True)\n",
    "plt.title('Distribution of Number of Shares')\n",
    "plt.xlabel('Number of Shares')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0ebd7b-3868-435d-8be9-c59ec12c105f",
   "metadata": {},
   "source": [
    "The distribution of shares is highly skewed, indicating that most articles receive a low number of shares, while a few go viral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b18f591-ff7e-4e76-8d72-3d7b1a27ffe4",
   "metadata": {},
   "source": [
    "### Log Transformation of Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbb171d-54ed-47ab-bd3a-beb844e60742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying log transformation to the target variable\n",
    "if 'shares' in df_clean.columns:\n",
    "    df_clean['log_shares'] = np.log1p(df_clean['shares'])\n",
    "    print(\"'log_shares' column created successfully.\")\n",
    "else:\n",
    "    print(\"'shares' column not found in df_clean.\")\n",
    "\n",
    "# Plotting the transformed target variable\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(df['log_shares'], bins=50, kde=True)\n",
    "plt.title('Distribution of Log-Transformed Number of Shares')\n",
    "plt.xlabel('Log(Number of Shares)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a898e092-d68e-49f8-a3bf-60b088d356b2",
   "metadata": {},
   "source": [
    "The log transformation normalizes the distribution, making it more suitable for regression modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea84d0ec-778f-4724-a856-047245a9cb75",
   "metadata": {},
   "source": [
    "### 2. Checking for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e1392a-1bb2-4e71-a571-1dfd76d94e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values[missing_values > 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf51b02-013d-4a6d-ae19-66f4195eabb2",
   "metadata": {},
   "source": [
    "There are no missing values in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165b11b9-e832-4c3d-a620-673ab633de54",
   "metadata": {},
   "source": [
    "### 3. Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4990ecf-7515-445e-9d1b-92d447b7bcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6c7028-d1e5-45fb-9d6c-67442f66ad43",
   "metadata": {},
   "source": [
    "### 4. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0998a9-29d8-4cd4-837e-1572d1eca0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "plt.figure(figsize=(20,20))\n",
    "corr_matrix = df.corr()\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffe3a84-88eb-4578-904e-5155393ebcf3",
   "metadata": {},
   "source": [
    "# Correlation with target variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613e3081-9729-418f-aae4-e9f649f81026",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_with_target = corr_matrix['shares'].sort_values(ascending=False)\n",
    "print(\"Top 10 features positively correlated with shares:\")\n",
    "print(corr_with_target.tail(-1).tail(10))\n",
    "\n",
    "print(\"\\nTop 10 features negatively correlated with shares:\")\n",
    "print(corr_with_target.tail(-1).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f133c2-82a7-430c-af88-26eee4adbb77",
   "metadata": {},
   "source": [
    "### Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fefbf1-1fc8-4afb-80e3-bd891841d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting top 5 positively and negatively correlated features\n",
    "top_positive_features = corr_with_target[1:6].index.tolist()  # Top 5 positive\n",
    "top_negative_features = corr_with_target[-5:].index.tolist()  # Top 5 negative\n",
    "\n",
    "# Combine both lists\n",
    "top_features = top_positive_features + top_negative_features\n",
    "\n",
    "# Plotting distributions\n",
    "for feature in top_features:\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.scatterplot(x=df_clean[feature], y=df_clean['shares'])\n",
    "    plt.title(f'Shares vs {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Shares')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1b82f2-6364-48c5-9570-97d6b50c4510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4861fae-8b08-4b8f-9897-4fdf412cbce6",
   "metadata": {},
   "source": [
    "### 5. Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f2a7d2-5cfb-4f9c-a665-9938fa6c6afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using absolute correlation for feature selection\n",
    "corr_with_target_abs = corr_matrix[target].abs().sort_values(ascending=False)\n",
    "\n",
    "# Selecting top 30 features based on absolute correlation, excluding the target\n",
    "top_corr_features = corr_with_target_abs[1:31].index.tolist()\n",
    "\n",
    "# Subset the data\n",
    "X_selected = df_clean[top_corr_features]\n",
    "y = df_clean[target]\n",
    "\n",
    "# Splitting into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Converting back to DataFrame\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=top_corr_features, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=top_corr_features, index=X_test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2784a4-1e60-4465-80e0-a7237f6f0a5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ad1a38-0e4a-4543-aa67-aec91407d554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f7de6a7-e391-4af1-a425-1f2a1d289737",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "- #### Feature Importance Using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0470e2-171d-44b0-ae4c-10364b7288a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'shares' is not in the feature list\n",
    "top_corr_features = [feature for feature in top_corr_features if feature != 'shares']\n",
    "\n",
    "# Training the Random Forest model with the corrected feature set\n",
    "rf_initial = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_initial.fit(X_train_scaled[top_corr_features], y_train)\n",
    "\n",
    "# Getting feature importances\n",
    "importances = rf_initial.feature_importances_\n",
    "feature_importances = pd.Series(importances, index=top_corr_features).sort_values(ascending=False)\n",
    "\n",
    "# Plotting feature importances\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.barplot(x=feature_importances, y=feature_importances.index)\n",
    "plt.title('Feature Importances')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Features')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa9ada0-c000-46b0-aa1b-ab9f540853a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de54c4c2-8c5f-4dc9-affb-babf8bfe4286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c63145f-c780-410c-b994-26e0abb9f30c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a648c0e7-dc18-4a2c-ab3d-876108f50394",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b7c2d32-5e5e-4061-bc9a-12db4abab2b0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cf65a8-4967-49e0-a3e6-521f8303be45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f21703-c8ca-4e6d-a679-0e18f899791d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389c2f6f-0545-4188-98db-21c9f4eac44f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c8fbad-7be2-471d-ae28-4b28f5674c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4c16471-03ac-456d-9222-d8bfd9524a3e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2c56e76-5526-45fb-8f96-cd84ccc99691",
   "metadata": {},
   "source": [
    "### Model Building and Training\n",
    "\n",
    "- #### Train multiple regression models to compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f753f170-ab55-4b8d-a973-1d52dad3c309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing and training Linear Regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = lr.predict(X_test_scaled)\n",
    "\n",
    "# Initializing and training Decision Tree Regressor\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "dt.fit(X_train_scaled, y_train)\n",
    "y_pred_dt = dt.predict(X_test_scaled)\n",
    "\n",
    "# Initializing and training K-Nearest Neighbors Regressor\n",
    "knn = KNeighborsRegressor()\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_pred_knn = knn.predict(X_test_scaled)\n",
    "\n",
    "# Initializing and training Random Forest Regressor\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "y_pred_rf = rf.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e941d06-d8a3-4423-bcef-4ae6aac09f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23686020-e72d-44d4-afd3-cf37b6779cbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fdd4369-64ee-4b8c-a676-efb80aae2611",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with GridSearchCV\n",
    "\n",
    "#### - Optimize the Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc2d9c9-6285-4ad5-bc71-14c58777cf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Initializing GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid,\n",
    "                           cv=3, n_jobs=-1, verbose=2, scoring='r2')\n",
    "\n",
    "# Fitting GridSearchCV\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Best parameters\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Best estimator\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Predicting with the best estimator\n",
    "y_pred_best_rf = best_rf.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae56bcb-6122-499e-9f8c-dc32594fb441",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "#### - Evaluate all models using MAE, MSE, RMSE, and R²."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dd1ff6-4365-4028-a1bc-ad7a3a6f01e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining evaluation function\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"--- {model_name} ---\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"MSE: {mse:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"R²: {r2:.4f}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4806d161-1880-4594-ab77-eff63a751d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating Linear Regression\n",
    "evaluate_model(y_test, y_pred_lr, \"Linear Regression\")\n",
    "\n",
    "# Evaluating Decision Tree Regressor\n",
    "evaluate_model(y_test, y_pred_dt, \"Decision Tree Regressor\")\n",
    "\n",
    "# Evaluating K-Nearest Neighbors Regressor\n",
    "evaluate_model(y_test, y_pred_knn, \"K-Nearest Neighbors Regressor\")\n",
    "\n",
    "# Evaluating Random Forest Regressor\n",
    "evaluate_model(y_test, y_pred_rf, \"Random Forest Regressor\")\n",
    "\n",
    "# Evaluating Tuned Random Forest Regressor\n",
    "evaluate_model(y_test, y_pred_best_rf, \"Tuned Random Forest Regressor\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a54c580-d703-4fa0-94b8-b13d154651d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing R² scores\n",
    "models = ['Linear Regression', 'Decision Tree', 'KNN', 'Random Forest', 'Tuned Random Forest']\n",
    "r2_scores = [\n",
    "    r2_score(y_test, y_pred_lr),\n",
    "    r2_score(y_test, y_pred_dt),\n",
    "    r2_score(y_test, y_pred_knn),\n",
    "    r2_score(y_test, y_pred_rf),\n",
    "    r2_score(y_test, y_pred_best_rf)\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=models, y=r2_scores)\n",
    "plt.title('R² Scores of Different Models')\n",
    "plt.ylabel('R² Score')\n",
    "plt.xlabel('Models')\n",
    "plt.ylim(0,1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3eee7de-f03f-4321-8ab5-e3e183c176c3",
   "metadata": {},
   "source": [
    "### Results and Discussion\n",
    "#### - Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d0565e-35ac-49de-8d31-2eb62ddfa518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals for Tuned Random Forest\n",
    "residuals = y_test - y_pred_best_rf\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(residuals, bins=50, kde=True)\n",
    "plt.title('Distribution of Residuals (Tuned Random Forest)')\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Residuals vs Predicted\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(x=y_pred_best_rf, y=residuals)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.title('Residuals vs Predicted Values (Tuned Random Forest)')\n",
    "plt.xlabel('Predicted Shares')\n",
    "plt.ylabel('Residuals')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a502abe-d65c-437f-aaa1-c2af04207f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SHAP explainer\n",
    "explainer = shap.Explainer(best_rf, X_train_scaled)\n",
    "shap_values = explainer(X_test_scaled)\n",
    "\n",
    "# Summary plot\n",
    "shap.summary_plot(shap_values, X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8a8a50-76b5-4328-914f-54c09c18ec8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
