{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "45afe8e1386bb813621db67c1e85d2c1",
     "grade": false,
     "grade_id": "cell-8a70a56233894d42",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Homework 2\n",
    "***\n",
    "**Name**: $<$insert name here$>$ \n",
    "***\n",
    "\n",
    "Remember that you are encouraged to discuss the problems with your instructors and classmates, but **you must write all code and solutions on your own**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1b98fbdff894309fe3937b7d4d55eb34",
     "grade": false,
     "grade_id": "cell-d3925f1a2ed0ba39",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The rules to be followed for the assignment are:\n",
    "\n",
    "- Do **NOT** load additional packages beyond what we've shared in the cells below. \n",
    "- Some problems with code may be autograded.  If we provide a function or class API **do not** change it.\n",
    "- Do not change the location of the data or data directory.  Use only relative paths to access the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T01:22:03.370195Z",
     "start_time": "2020-09-10T01:22:02.356211Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "728bb8c12435a7d8af07857e799b9025",
     "grade": false,
     "grade_id": "cell-76950cd59a275b9b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c78a88f5de1e17ba4a6a9bc1ce64784",
     "grade": false,
     "grade_id": "cell-eeb3bd05ca5a2672",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Problem 1\n",
    "***\n",
    "\n",
    "There are two functions that need to be completed:\n",
    "\n",
    "#### normalization(fname, attr, normType)\n",
    "\n",
    "- This function takes in the location of the data file, the attribute that has to be normalised (one of the values from 'Open','High','Low','Close','Volume', given as column indices) and the type of normalization to be performed ('min_max' or 'z_score')\n",
    "\n",
    "- Based on the normalisation type that is mentioned, you will have to apply the appropriate formula and return a dictionary where key = original value in the dataset, value = normalised value\n",
    "\n",
    "- A sample dataset has been provided to you at this location \"./data/HistoricalQuotes.csv\". Use this dataset to test the functionality you are building.\n",
    "\n",
    "#### correlation (fname1, attr1, fname2, attr2)\n",
    "\n",
    "- This function takes in the location of the first data file, the attribute that has to be used in the first file, the location of the second data file and the attribute that has to be used in the second file.\n",
    "\n",
    "- This function has to calculate the correlation coefficient between the two attributes mentioned in the two files.\n",
    "\n",
    "- Two Sample datasets have been provided to you in \"./data/test1.csv\" and \"./data/test2.csv\" respectively.\n",
    "\n",
    "- The two sample files have the following attributes 'Open','High','Last','Low','Volume'. Use these two sample files to test the functionality you are building.\n",
    "\n",
    "Note:\n",
    "- If the test case fails, one way to debug is to see the output of the testing data and comparing it to your output.\n",
    "- Initially the test case will be failed as there is no code in the below two functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T01:24:33.428213Z",
     "start_time": "2020-09-10T01:24:33.423898Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5bc7e76c2c1a5ce1942a310ff8c6ce8f",
     "grade": false,
     "grade_id": "normalization",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{38.1: 0.7637474541751528,\n",
       " 38.4301: 0.77409055303149,\n",
       " 40.96: 0.8533604887983707,\n",
       " 41.36: 0.8658937803540655,\n",
       " 40.14: 0.8276672411091963,\n",
       " 40.565: 0.8409838633871219,\n",
       " 40.42: 0.8364405451981827,\n",
       " 40.07: 0.8254739150869497,\n",
       " 40.0: 0.8232805890647031,\n",
       " 39.32: 0.801973993420022,\n",
       " 39.64: 0.8120006266645777,\n",
       " 38.7: 0.782547391508695,\n",
       " 38.3: 0.7700140999530001,\n",
       " 38.06: 0.7624941250195834,\n",
       " 37.74: 0.7524674917750275,\n",
       " 37.27: 0.7377408741970861,\n",
       " 37.28: 0.7380542064859784,\n",
       " 37.37: 0.7408741970860097,\n",
       " 36.8207: 0.7236628544571518,\n",
       " 36.71: 0.7201942660191133,\n",
       " 37.31: 0.7389942033526555,\n",
       " 36.73: 0.7208209305968979,\n",
       " 36.49: 0.7133009556634812,\n",
       " 36.41: 0.710794297352342,\n",
       " 35.65: 0.686981043396522,\n",
       " 35.9038: 0.6949334168886102,\n",
       " 35.97: 0.6970076766410778,\n",
       " 36.38: 0.7098543004856651,\n",
       " 36.09: 0.7007676641077863,\n",
       " 37.14: 0.7336675544414852,\n",
       " 37.5: 0.7449475168416105,\n",
       " 36.25: 0.7057809807300642,\n",
       " 37.0: 0.729280902396992,\n",
       " 35.8: 0.6916810277299075,\n",
       " 34.73: 0.6581544728184238,\n",
       " 34.0: 0.6352812157292809,\n",
       " 34.6207: 0.6547297509008303,\n",
       " 33.44: 0.617734607551308,\n",
       " 33.76: 0.6277612407958639,\n",
       " 34.86: 0.6622277925740248,\n",
       " 34.81: 0.6606611311295629,\n",
       " 32.73: 0.5954880150399497,\n",
       " 31.765: 0.5652514491618361,\n",
       " 31.155: 0.5461381795394016,\n",
       " 30.395: 0.5223249255835815,\n",
       " 30.06: 0.5118282939056871,\n",
       " 29.02: 0.4792417358608805,\n",
       " 28.23: 0.45448848503838324,\n",
       " 28.75: 0.4707817640607865,\n",
       " 30.82: 0.5356415478615071,\n",
       " 31.34: 0.5519348268839105,\n",
       " 32.7301: 0.5954911483628388,\n",
       " 32.95: 0.6023813253955821,\n",
       " 33.4: 0.6164812783957386,\n",
       " 33.86: 0.6308945636847877,\n",
       " 34.1: 0.6384145386182046,\n",
       " 34.21: 0.6418611937960207,\n",
       " 32.84: 0.598934670217766,\n",
       " 32.47: 0.5873413755287482,\n",
       " 32.72: 0.5951746827510574,\n",
       " 34.9: 0.6634811217295942,\n",
       " 35.163000000000004: 0.6717217609274637,\n",
       " 35.75: 0.6901143662854456,\n",
       " 34.47: 0.6500078333072222,\n",
       " 33.34: 0.6146012846623845,\n",
       " 32.44: 0.586401378662071,\n",
       " 31.61: 0.5603947986840043,\n",
       " 30.84: 0.5362682124392919,\n",
       " 30.29: 0.5190349365502115,\n",
       " 31.32: 0.5513081623061257,\n",
       " 32.235: 0.5799780667397775,\n",
       " 33.36: 0.6152279492401691,\n",
       " 31.775: 0.5655647814507284,\n",
       " 31.39: 0.5535014883283722,\n",
       " 30.45: 0.5240482531724895,\n",
       " 29.325: 0.48879837067209775,\n",
       " 29.56: 0.49616167946106843,\n",
       " 28.11: 0.45072849757167477,\n",
       " 27.12: 0.41970860097133017,\n",
       " 27.58: 0.4341218862603791,\n",
       " 29.09: 0.48143506188312707,\n",
       " 29.3318: 0.4890114366285446,\n",
       " 28.74: 0.47046843177189407,\n",
       " 27.94: 0.44540184866050453,\n",
       " 27.553: 0.4332758890803698,\n",
       " 27.9: 0.44414851950493495,\n",
       " 27.39: 0.4281685727714241,\n",
       " 27.1915: 0.4219489268369106,\n",
       " 28.085: 0.4499451668494439,\n",
       " 29.62: 0.4980416731944227,\n",
       " 28.5734: 0.4652483158389472,\n",
       " 29.13: 0.48268839103869654,\n",
       " 27.46: 0.43036189879367076,\n",
       " 27.73: 0.4388218705937647,\n",
       " 26.45: 0.3987153376155413,\n",
       " 25.055: 0.3550054833150556,\n",
       " 26.11: 0.3880620397932007,\n",
       " 26.47: 0.399342002193326,\n",
       " 25.955: 0.3832053893153689,\n",
       " 26.75: 0.4081153062823124,\n",
       " 27.6: 0.43474855083816394,\n",
       " 26.24: 0.39213535954880147,\n",
       " 27.28: 0.42472191759360806,\n",
       " 25.92: 0.38210872630424575,\n",
       " 25.3102: 0.3630017233275889,\n",
       " 23.79: 0.31536894877017074,\n",
       " 22.75: 0.28278239072536426,\n",
       " 22.36: 0.2705624314585618,\n",
       " 23.05: 0.2921823593921354,\n",
       " 24.4: 0.33448221839260533,\n",
       " 24.6: 0.3407488641704528,\n",
       " 24.76: 0.34576218079273074,\n",
       " 25.625: 0.3728654237819207,\n",
       " 24.52: 0.3382422058593138,\n",
       " 24.13: 0.32602224659251133,\n",
       " 23.5: 0.30628231239229203,\n",
       " 23.7: 0.31254895817013945,\n",
       " 20.6558: 0.21716434278552404,\n",
       " 20.0: 0.19661601127996242,\n",
       " 23.18: 0.2962556791477362,\n",
       " 23.92: 0.3194422685257717,\n",
       " 26.4001: 0.39715180949396833,\n",
       " 26.7: 0.4065486448378505,\n",
       " 30.01: 0.5102616324612252,\n",
       " 33.12: 0.6077079743067522,\n",
       " 30.62: 0.5293749020836598,\n",
       " 32.51: 0.5885947046843176,\n",
       " 34.52: 0.6515744947516843,\n",
       " 34.77: 0.6594078019739935,\n",
       " 34.41: 0.648127839573868,\n",
       " 35.14: 0.6710010966630111,\n",
       " 31.51: 0.5572614757950808,\n",
       " 34.435: 0.648911170296099,\n",
       " 34.885: 0.6630111232962556,\n",
       " 35.3: 0.6760144132852889,\n",
       " 38.04: 0.7618674604417984,\n",
       " 37.955: 0.7592041359862133,\n",
       " 37.935: 0.7585774714084287,\n",
       " 36.68: 0.7192542691524362,\n",
       " 36.58: 0.7161209462635124,\n",
       " 36.21: 0.7045276515744947,\n",
       " 36.17: 0.7032743224189253,\n",
       " 35.535: 0.6833777220742596,\n",
       " 36.84: 0.7242675857747142,\n",
       " 36.42: 0.7111076296412345,\n",
       " 33.19: 0.6099013003289988,\n",
       " 32.45: 0.5867147109509635,\n",
       " 32.08: 0.5751214162619457,\n",
       " 32.39: 0.5848347172176093,\n",
       " 33.2927: 0.6131192229359236,\n",
       " 32.85: 0.5992480025066583,\n",
       " 32.15: 0.5773147422841923,\n",
       " 32.97: 0.6030079899733667,\n",
       " 33.72: 0.6265079116402945,\n",
       " 33.955: 0.6338712204292651,\n",
       " 33.87: 0.63120789597368,\n",
       " 33.58: 0.6221212595958012,\n",
       " 33.03: 0.604887983706721,\n",
       " 32.64: 0.5926680244399185,\n",
       " 32.49: 0.587968040106533,\n",
       " 32.46: 0.5870280432398559,\n",
       " 33.0: 0.6039479868400438,\n",
       " 32.35: 0.5835813880620399,\n",
       " 31.72: 0.5638414538618204,\n",
       " 31.16: 0.5462948456838478,\n",
       " 31.26: 0.5494281685727715,\n",
       " 31.96: 0.5713614287952373,\n",
       " 31.77: 0.5654081153062824,\n",
       " 31.82: 0.5669747767507441,\n",
       " 32.22: 0.5795080683064389,\n",
       " 32.4211: 0.5858091806360646,\n",
       " 32.42: 0.5857747140842864,\n",
       " 31.99: 0.5723014256619144,\n",
       " 31.54: 0.5582014726617578,\n",
       " 30.6315: 0.529735234215886,\n",
       " 30.63: 0.5296882343725522,\n",
       " 30.41: 0.5227949240169201,\n",
       " 30.24: 0.5174682751057497,\n",
       " 29.93: 0.5077549741500861,\n",
       " 29.86: 0.5055616481278395,\n",
       " 29.77: 0.5027416575278083,\n",
       " 30.12: 0.5137082876390413,\n",
       " 29.98: 0.5093216355945481,\n",
       " 29.92: 0.5074416418611938,\n",
       " 29.91: 0.5071283095723015,\n",
       " 29.48: 0.49365502114992954,\n",
       " 29.97: 0.5090083033056556,\n",
       " 30.78: 0.5343882187059377,\n",
       " 30.93: 0.5390882030393231,\n",
       " 30.4: 0.5224815917280276,\n",
       " 30.05: 0.5115149616167947,\n",
       " 29.575: 0.49663167789440704,\n",
       " 29.15: 0.48331505561648125,\n",
       " 28.88: 0.47485508381638725,\n",
       " 29.18: 0.4842550524831584,\n",
       " 29.01: 0.4789284035719882,\n",
       " 28.91: 0.4757950806830644,\n",
       " 28.73: 0.47015509948300177,\n",
       " 28.93: 0.4764217452608491,\n",
       " 28.92: 0.47610841297195683,\n",
       " 29.05: 0.4801817327275576,\n",
       " 28.63: 0.467021776594078,\n",
       " 29.4: 0.49114836283879054,\n",
       " 29.71: 0.5008616637944541,\n",
       " 29.61: 0.4977283409055303,\n",
       " 29.41: 0.49146169512768295,\n",
       " 28.84: 0.47360175466081783,\n",
       " 29.72: 0.5011749960833464,\n",
       " 29.82: 0.50430831897227,\n",
       " 29.75: 0.5021149929500235,\n",
       " 30.51: 0.5259282469058438,\n",
       " 37.76: 0.7530941563528121,\n",
       " 38.78: 0.785054049819834,\n",
       " 39.31: 0.8016606611311297,\n",
       " 38.27: 0.7690741030863231,\n",
       " 39.41: 0.8047939840200531,\n",
       " 39.595: 0.8105906313645621,\n",
       " 39.35: 0.8029139902866991,\n",
       " 39.47: 0.8066739777534074,\n",
       " 39.805: 0.8171706094313018,\n",
       " 39.26: 0.8000939996866676,\n",
       " 39.22: 0.7988406705310982,\n",
       " 39.67: 0.812940623531255,\n",
       " 40.06: 0.8251605827980574,\n",
       " 39.83: 0.8179539401535327,\n",
       " 38.61: 0.7797274009086635,\n",
       " 39.25: 0.7997806673977753,\n",
       " 40.0304: 0.824233119222936,\n",
       " 40.815: 0.8488171706094312,\n",
       " 40.61: 0.8423938586871377,\n",
       " 41.72: 0.8771737427541908,\n",
       " 41.18: 0.8602537991540028,\n",
       " 41.06: 0.8564938116872944,\n",
       " 42.85: 0.9125802913990287,\n",
       " 42.94: 0.9154002819990599,\n",
       " 42.68: 0.9072536424878583,\n",
       " 42.39: 0.8981670061099797,\n",
       " 42.88: 0.9135202882657059,\n",
       " 42.19: 0.8919003603321322,\n",
       " 42.33: 0.8962870123766253,\n",
       " 43.11: 0.9207269309102303,\n",
       " 43.05: 0.9188469371768759,\n",
       " 42.51: 0.901926993576688,\n",
       " 43.84: 0.9436001879993734,\n",
       " 44.56: 0.9661601127996241,\n",
       " 43.62: 0.936706877643741,\n",
       " 42.11: 0.8893937020209932,\n",
       " 41.64: 0.8746670844430519,\n",
       " 41.9: 0.8828137239542534,\n",
       " 41.82: 0.8803070656431146,\n",
       " 41.3: 0.8640137866207112,\n",
       " 41.53: 0.8712204292652358,\n",
       " 41.0: 0.8546138179539401,\n",
       " 40.81: 0.8486605044649852,\n",
       " 41.59: 0.8731004229985901,\n",
       " 42.36: 0.8972270092433025,\n",
       " 41.38: 0.8665204449318503,\n",
       " 41.05: 0.8561804793984019,\n",
       " 40.11: 0.8267272442425192,\n",
       " 39.775: 0.8162306125646247,\n",
       " 40.39: 0.8355005483315056,\n",
       " 40.38: 0.8351872160426133,\n",
       " 40.3941: 0.8356290145699514,\n",
       " 40.94: 0.8527338242205859,\n",
       " 40.33: 0.8336205545981512,\n",
       " 40.78: 0.847720507598308,\n",
       " 39.615: 0.8112172959423469,\n",
       " 41.7236: 0.8772865423781919,\n",
       " 41.01: 0.8549271502428324,\n",
       " 40.82: 0.8489738367538775,\n",
       " 40.9: 0.8514804950650163,\n",
       " 37.91: 0.7577941406861975,\n",
       " 36.82: 0.7236409211969294,\n",
       " 36.83: 0.7239542534858217,\n",
       " 37.56: 0.7468275105749648,\n",
       " 37.82: 0.7549741500861664,\n",
       " 37.9435: 0.7588438038539871,\n",
       " 37.17: 0.7346075513081624,\n",
       " 36.97: 0.7283409055303148,\n",
       " 36.88: 0.7255209149302836,\n",
       " 36.29: 0.7070343098856336,\n",
       " 35.87: 0.693874353752154,\n",
       " 35.6: 0.6854143819520602,\n",
       " 35.94: 0.6960676797744006,\n",
       " 35.885: 0.6943443521854926,\n",
       " 35.224000000000004: 0.6736330878897071,\n",
       " 34.28: 0.6440545198182673,\n",
       " 34.61: 0.6543944853517154,\n",
       " 34.92: 0.664107786307379,\n",
       " 34.57: 0.653141156196146,\n",
       " 34.82: 0.6609744634184552,\n",
       " 34.99: 0.6663011123296256,\n",
       " 35.33: 0.6769544101519661,\n",
       " 35.81: 0.6919943600188,\n",
       " 36.55: 0.7151809493968352,\n",
       " 36.11: 0.7013943286855711,\n",
       " 36.04: 0.6992010026633244,\n",
       " 35.76: 0.690427698574338,\n",
       " 37.05: 0.7308475638414538,\n",
       " 36.854: 0.7247062509791633,\n",
       " 37.62: 0.7487075043083189,\n",
       " 36.8: 0.7230142566191445,\n",
       " 35.96: 0.6966943443521855,\n",
       " 35.9543: 0.6965157449475169,\n",
       " 34.97: 0.6656744477518408,\n",
       " 34.04: 0.6365345448848503,\n",
       " 36.3: 0.707347642174526,\n",
       " 36.6: 0.7167476108412972,\n",
       " 36.5237: 0.7143568854770483,\n",
       " 37.23: 0.7364875450415164,\n",
       " 37.24: 0.7368008773304089,\n",
       " 37.33: 0.7396208679304401,\n",
       " 36.92: 0.7267742440858531,\n",
       " 37.47: 0.7440075199749333,\n",
       " 38.05: 0.7621807927306908,\n",
       " 36.6425: 0.7180792730690897,\n",
       " 36.37: 0.7095409681967726,\n",
       " 37.86: 0.7562274792417358,\n",
       " 37.8203: 0.7549835500548332,\n",
       " 38.33: 0.7709540968196772,\n",
       " 38.12: 0.7643741187529374,\n",
       " 39.45: 0.8060473131756228,\n",
       " 39.96: 0.8220272599091336,\n",
       " 38.84: 0.7869340435531882,\n",
       " 39.65: 0.8123139589534701,\n",
       " 38.63: 0.7803540654864485,\n",
       " 38.18: 0.7662541124862917,\n",
       " 38.19: 0.766567444775184,\n",
       " 38.8: 0.7856807143976186,\n",
       " 36.91: 0.7264609117969606,\n",
       " 33.82: 0.6296412345292182,\n",
       " 34.32: 0.6453078489738368,\n",
       " 34.2: 0.6415478615071284,\n",
       " 34.23: 0.6424878583738053,\n",
       " 34.34: 0.6459345135516216,\n",
       " 34.11: 0.6387278709070969,\n",
       " 34.5125: 0.6513394955350149,\n",
       " 34.8068: 0.6605608647971174,\n",
       " 34.51: 0.6512611624627918,\n",
       " 34.37: 0.6468745104182985,\n",
       " 33.9: 0.6321478928403571,\n",
       " 33.81: 0.6293279022403259,\n",
       " 33.23: 0.6111546294845682,\n",
       " 32.7: 0.5945480181732729,\n",
       " 31.73: 0.5641547861507129,\n",
       " 31.95: 0.571048096506345,\n",
       " 32.92: 0.601441328528905,\n",
       " 32.28: 0.5813880620397932,\n",
       " 32.34: 0.5832680557731476,\n",
       " 32.03: 0.573554754817484,\n",
       " 30.88: 0.5375215415948614,\n",
       " 30.71: 0.532194892683691,\n",
       " 30.94: 0.5394015353282157,\n",
       " 31.04: 0.5425348582171392,\n",
       " 30.885: 0.5376782077393076,\n",
       " 30.585: 0.5282782390725365,\n",
       " 30.39: 0.5221682594391351,\n",
       " 30.065: 0.5119849600501333,\n",
       " 30.28: 0.5187216042613191,\n",
       " 29.9: 0.506814977283409,\n",
       " 30.99: 0.5409681967726775,\n",
       " 31.88: 0.5688547704840984,\n",
       " 30.81: 0.5353282155726148,\n",
       " 30.6: 0.528748237505875,\n",
       " 31.21: 0.5478615071283096,\n",
       " 31.15: 0.5459815133949553,\n",
       " 30.97: 0.5403415321948927,\n",
       " 30.55: 0.5271815760614132,\n",
       " 30.23: 0.5171549428168574,\n",
       " 29.6598: 0.49928873570421434,\n",
       " 29.42: 0.49177502741657536,\n",
       " 30.31: 0.5196616011279963,\n",
       " 33.75: 0.6274479085069716,\n",
       " 33.92: 0.6327745574181419,\n",
       " 33.24: 0.6114679617734607,\n",
       " 32.96: 0.6026946576844744,\n",
       " 32.79: 0.597368008773304,\n",
       " 31.42: 0.5544414851950493,\n",
       " 31.46: 0.5556948143506188,\n",
       " 32.12: 0.5763747454175152,\n",
       " 31.98: 0.5719880933730221,\n",
       " 30.91: 0.5384615384615385,\n",
       " 30.72: 0.5325082249725833,\n",
       " 31.925: 0.5702647657841141,\n",
       " 32.77: 0.5967413441955194,\n",
       " 32.43: 0.5860880463731787,\n",
       " 32.26: 0.5807613974620084,\n",
       " 29.768: 0.5026789910700298,\n",
       " 28.31: 0.4569951433495221,\n",
       " 27.87: 0.44320852263825794,\n",
       " 28.34: 0.4579351402161993,\n",
       " 27.84: 0.44226852577158077,\n",
       " 27.26: 0.42409525301582335,\n",
       " 26.8: 0.4096819677267743,\n",
       " 26.26: 0.39276202412658634,\n",
       " 27.04: 0.4172019426601911,\n",
       " 28.51: 0.46326178912736965,\n",
       " 32.66: 0.5932946890177031,\n",
       " 33.08: 0.6064546451511827,\n",
       " 33.2: 0.6102146326178913,\n",
       " 35.05: 0.6681811060629796,\n",
       " 34.85: 0.6619144602851325,\n",
       " 33.88: 0.6315212282625725,\n",
       " 32.255: 0.5806047313175623,\n",
       " 32.675: 0.5937646874510417,\n",
       " 31.11: 0.5447281842393858,\n",
       " 32.5: 0.5882813723954253,\n",
       " 32.21: 0.5791947360175466,\n",
       " 30.11: 0.5133949553501488,\n",
       " 29.87: 0.5058749804167321,\n",
       " 32.36: 0.5838947203509322,\n",
       " 31.52: 0.5575748080839731,\n",
       " 31.1: 0.5444148519504936,\n",
       " 29.94: 0.5080683064389787,\n",
       " 31.84: 0.567601441328529,\n",
       " 32.6: 0.5914146952843491,\n",
       " 32.62: 0.5920413598621337,\n",
       " 32.75: 0.5961146796177346,\n",
       " 31.47: 0.5560081466395111,\n",
       " 31.78: 0.5657214475951747,\n",
       " 33.39: 0.6161679461068463,\n",
       " 34.38: 0.647187842707191,\n",
       " 33.84: 0.6302678991070031,\n",
       " 33.37: 0.6155412815290615,\n",
       " 33.85: 0.6305812313958954,\n",
       " 34.35: 0.6462478458405139,\n",
       " 31.3: 0.550681497728341,\n",
       " 31.62: 0.5607081309728968,\n",
       " 30.76: 0.5337615541281531,\n",
       " 27.305: 0.42550524831583897,\n",
       " 28.07: 0.4494751684161053,\n",
       " 28.68: 0.4685884380385399,\n",
       " 28.975: 0.47783174056086486,\n",
       " 28.96: 0.4773617421275263,\n",
       " 27.59: 0.43443521854927153,\n",
       " 26.19: 0.3905686981043397,\n",
       " 26.7614: 0.4084725050916497,\n",
       " 27.72: 0.4385085383048723,\n",
       " 27.97: 0.4463418455271816,\n",
       " 28.25: 0.45511514961616795,\n",
       " 27.91: 0.44446185179382736,\n",
       " 28.0: 0.4472818423938587,\n",
       " 28.41: 0.4601284662384459,\n",
       " 28.8: 0.47234842550524836,\n",
       " 28.44: 0.46106846310512306,\n",
       " 27.93: 0.4450885163716121,\n",
       " 28.49: 0.46263512454958483,\n",
       " 29.24: 0.4861350462165126,\n",
       " 28.82: 0.47297509008303307,\n",
       " 28.43: 0.46075513081623065,\n",
       " 29.25: 0.486448378505405,\n",
       " 30.35: 0.5209149302835657,\n",
       " 29.9531: 0.5084787717374275,\n",
       " 34.48: 0.6503211655961145,\n",
       " 34.59: 0.6537678207739308,\n",
       " 35.21: 0.6731944226852578,\n",
       " 34.89: 0.6631677894407019,\n",
       " 33.9279: 0.6330220899263669,\n",
       " 33.35: 0.6149146169512768,\n",
       " 32.2: 0.5788814037286543,\n",
       " 32.415: 0.5856180479398402,\n",
       " 31.951: 0.5710794297352342,\n",
       " 32.515: 0.5887513708287639,\n",
       " 32.02: 0.5732414225285917,\n",
       " 31.81: 0.5666614444618518,\n",
       " 32.55: 0.589848033839887,\n",
       " 31.45: 0.5553814820617266,\n",
       " 31.8: 0.5663481121729596,\n",
       " 31.07: 0.5434748550838163,\n",
       " 42.14: 0.8903336988876703,\n",
       " 42.35: 0.8969136769544102,\n",
       " 42.4: 0.898480338398872,\n",
       " 43.23: 0.9244869183769386,\n",
       " 42.74: 0.9091336362212127,\n",
       " 43.15: 0.9219802600657997,\n",
       " 43.91: 0.9457935140216198,\n",
       " 43.93: 0.9464201785994046,\n",
       " 44.36: 0.9598934670217766,\n",
       " 42.22: 0.8928403571988093,\n",
       " 43.63: 0.9370202099326336,\n",
       " 42.08: 0.8884537051543161,\n",
       " 44.61: 0.9677267742440858,\n",
       " 43.55: 0.9345135516214945,\n",
       " 43.8: 0.9423468588438038,\n",
       " 42.75: 0.909446968510105,\n",
       " 43.56: 0.934826883910387,\n",
       " 42.49: 0.9013003289989033,\n",
       " 43.68: 0.9385868713770954,\n",
       " 43.51: 0.933260222465925,\n",
       " 43.325: 0.9274635751214163,\n",
       " 44.5: 0.9642801190662698,\n",
       " 44.2: 0.9548801503994987,\n",
       " 45.4401: 0.9937364875450415,\n",
       " 43.57: 0.9351402161992793,\n",
       " 45.64: 1.0,\n",
       " 43.4199: 0.9304370985430048,\n",
       " 42.41: 0.8987936706877643,\n",
       " 40.66: 0.8439605201315994,\n",
       " 39.42: 0.8051073163089457,\n",
       " 38.64: 0.7806673977753408,\n",
       " 39.21: 0.7985273382422059,\n",
       " 39.19: 0.7979006736644211,\n",
       " 35.95: 0.6963810120632932,\n",
       " 35.09: 0.6694344352185494,\n",
       " 34.25: 0.6431145229515901,\n",
       " 34.08: 0.6377878740404198,\n",
       " 33.31: 0.6136612877957074,\n",
       " 32.83: 0.5986213379288735,\n",
       " 32.9: 0.60081466395112,\n",
       " 32.2108: 0.579219802600658,\n",
       " 32.281: 0.5814193952686824,\n",
       " 32.67: 0.5936080213065956,\n",
       " 32.93: 0.6017546608177973,\n",
       " 32.2501: 0.5804511984960051,\n",
       " 32.58: 0.5907880307065643,\n",
       " 31.94: 0.5707347642174527,\n",
       " 31.03: 0.5422215259282469,\n",
       " 29.85: 0.5052483158389472,\n",
       " 29.95: 0.508381638727871,\n",
       " 29.6: 0.497415008616638,\n",
       " 28.59: 0.46576844743850854,\n",
       " 28.14: 0.4516684944383519,\n",
       " 29.63: 0.49835500548331507,\n",
       " 30.85: 0.5365815447281842,\n",
       " 31.65: 0.5616481278395737,\n",
       " 30.96: 0.5400281999060003,\n",
       " 29.43: 0.49208835970546766,\n",
       " 28.36: 0.458561804793984,\n",
       " 28.78: 0.47172176092746365,\n",
       " 28.28: 0.4560551464828451,\n",
       " 28.1: 0.45041516528278247,\n",
       " 26.6: 0.40341532194892693,\n",
       " 27.22: 0.42284192386025377,\n",
       " 27.75: 0.43944853517154947,\n",
       " 27.88: 0.44352185492715024,\n",
       " 30.7: 0.5318815603947987,\n",
       " 30.7907: 0.5347234842550525,\n",
       " 31.175: 0.5467648441171864,\n",
       " 32.05: 0.5741814193952686,\n",
       " 30.61: 0.5290615697947673,\n",
       " 35.52: 0.6829077236409212,\n",
       " 35.4: 0.6791477361742126,\n",
       " 34.09: 0.6381012063293123,\n",
       " 34.83: 0.6612877957073475,\n",
       " 34.9367: 0.6646310512298292,\n",
       " 34.68: 0.656587811373962,\n",
       " 33.99: 0.6349678834403886,\n",
       " 31.49: 0.556634811217296,\n",
       " 31.97: 0.5716747610841296,\n",
       " 31.63: 0.5610214632617891,\n",
       " 32.6472: 0.592893623687921,\n",
       " 32.68: 0.593921353595488,\n",
       " 33.0599: 0.6058248472505091,\n",
       " 30.64: 0.5300015666614445,\n",
       " 30.8631: 0.5369920100266333,\n",
       " 29.68: 0.4999216669277769,\n",
       " 25.76: 0.3770954096819678,\n",
       " 24.2: 0.3282155726147579,\n",
       " 24.1: 0.3250822497258343,\n",
       " 25.7: 0.3752154159486135,\n",
       " 25.44: 0.3670687764374119,\n",
       " 25.14: 0.3576688077706408,\n",
       " 24.55: 0.339182202725991,\n",
       " 22.3: 0.2686824377252076,\n",
       " 22.04: 0.26053579821400596,\n",
       " 22.1: 0.26241579194736026,\n",
       " 22.41: 0.2721290929030237,\n",
       " 22.86: 0.2862290459031803,\n",
       " 23.72: 0.31317562274792415,\n",
       " 24.22: 0.3288422371925427,\n",
       " 24.51: 0.3379288735704215,\n",
       " 24.93: 0.351088829703901,\n",
       " 23.9: 0.3188156039479868,\n",
       " 23.76: 0.31442895190349374,\n",
       " 24.07: 0.32414225285915715,\n",
       " 23.88: 0.3181889393702021,\n",
       " 23.685: 0.31207895973680083,\n",
       " 23.85: 0.31724894250352503,\n",
       " 23.91: 0.3191289362368792,\n",
       " 24.17: 0.3272755757480809,\n",
       " 24.38: 0.3338555538148206,\n",
       " 24.7: 0.34388218705937645,\n",
       " 24.69: 0.34356885477048416,\n",
       " 23.13: 0.2946890177032743,\n",
       " 22.185: 0.2650791164029453,\n",
       " 21.62: 0.24737584208052646,\n",
       " 21.52: 0.2442425191916027,\n",
       " 21.625: 0.2475325082249726,\n",
       " 21.1: 0.2310825630581232,\n",
       " 20.95: 0.22638257872473758,\n",
       " 20.97: 0.2270092433025223,\n",
       " 20.4: 0.2091493028356572,\n",
       " 20.3: 0.20601597994673354,\n",
       " 20.225: 0.2036659877800408,\n",
       " 20.12: 0.2003759987466709,\n",
       " 20.51: 0.21259595801347336,\n",
       " 20.52: 0.21290929030236566,\n",
       " 21.56: 0.24549584834717214,\n",
       " 21.7: 0.24988250039166535,\n",
       " 22.17: 0.26460911796960684,\n",
       " 21.8: 0.2530158232805891,\n",
       " 21.15: 0.23264922450258496,\n",
       " 20.7: 0.2185492715024283,\n",
       " 20.25: 0.2044493185022717,\n",
       " 19.985: 0.19614601284662384,\n",
       " 19.73: 0.18815603947986842,\n",
       " 19.88: 0.19285602381325395,\n",
       " 19.93: 0.1944226852577158,\n",
       " 19.74: 0.18846937176876075,\n",
       " 19.36: 0.17656274479085068,\n",
       " 19.37: 0.17687607707974312,\n",
       " 19.51: 0.18126272912423633,\n",
       " 19.26: 0.17342942190192706,\n",
       " 19.52: 0.18157606141312863,\n",
       " 19.64: 0.1853360488798371,\n",
       " 20.46: 0.21102929656901148,\n",
       " 21.06: 0.22982923390255364,\n",
       " 20.15: 0.20131599561334793,\n",
       " 18.9: 0.16214945950180162,\n",
       " 17.03: 0.10355632147892846,\n",
       " 17.23: 0.10982296725677584,\n",
       " 17.34: 0.11326962243459189,\n",
       " 17.83: 0.128622904590318,\n",
       " 17.65: 0.12298292339025534,\n",
       " 17.97: 0.1330095566348112,\n",
       " 18.11: 0.1373962086793044,\n",
       " 18.23: 0.14115619614601288,\n",
       " 18.35: 0.14491618361272135,\n",
       " 17.73: 0.12548958170139435,\n",
       " 17.43: 0.11608961303462323,\n",
       " 17.39: 0.11483628387905377,\n",
       " 17.66: 0.12329625567914776,\n",
       " 17.74: 0.12580291399028667,\n",
       " 17.5: 0.11828293905686982,\n",
       " 17.12: 0.10637631207895978,\n",
       " 16.78: 0.0957230142566192,\n",
       " 16.75: 0.09478301738994205,\n",
       " 16.755: 0.0949396835343882,\n",
       " 16.57: 0.08914303618987938,\n",
       " 16.82: 0.09697634341218865,\n",
       " 17.42: 0.11577628074573092,\n",
       " 17.35: 0.11358295472348431,\n",
       " 17.51: 0.11859627134576224,\n",
       " 17.48: 0.1176562744790851,\n",
       " 17.47: 0.11734294219019267,\n",
       " 17.95: 0.13238289205702647,\n",
       " 17.94: 0.13206955976813417,\n",
       " 18.09: 0.13676954410151967,\n",
       " 17.7: 0.1245495848347172,\n",
       " 17.27: 0.11107629641234529,\n",
       " 17.08: 0.10512298292339022,\n",
       " 16.8301: 0.09729280902396999,\n",
       " 16.5162: 0.08745730847563847,\n",
       " 16.44: 0.0850697164342786,\n",
       " 16.58: 0.0894563684787717,\n",
       " 16.88: 0.09885633714554283,\n",
       " 16.8: 0.09634967883440392,\n",
       " 16.6: 0.09008303305655653,\n",
       " 16.61: 0.09039636534544884,\n",
       " 16.51: 0.0872630424565252,\n",
       " 16.14: 0.07566974776750747,\n",
       " 15.9301: 0.06909290302365659,\n",
       " 15.77: 0.06407645307848973,\n",
       " 15.86: 0.06689644367852107,\n",
       " 15.96: 0.07002976656744482,\n",
       " 15.93: 0.06908976970076766,\n",
       " 16.01: 0.07159642801190669,\n",
       " 15.67: 0.06094313018956605,\n",
       " 15.73: 0.06282312392292028,\n",
       " 16.05: 0.07284975716747615,\n",
       " 16.24: 0.0788030706564311,\n",
       " 16.1299: 0.07535328215572613,\n",
       " 15.945: 0.06955976813410625,\n",
       " 15.91: 0.06846310512298294,\n",
       " 16.0: 0.07128309572301426,\n",
       " 16.52: 0.08757637474541752,\n",
       " 16.5: 0.08694971016763278,\n",
       " 19.27: 0.17374275419081936,\n",
       " 19.69: 0.18690271032429898,\n",
       " 19.82: 0.19097603007989977,\n",
       " 20.18: 0.20225599248002507,\n",
       " 19.83: 0.19128936236879207,\n",
       " 19.41: 0.17812940623531257,\n",
       " 19.33: 0.17562274792417354,\n",
       " 19.08: 0.1677894407018643,\n",
       " 18.91: 0.16246279179069406,\n",
       " 18.1: 0.13708287639041208,\n",
       " 17.775: 0.12689957700140997,\n",
       " 17.63: 0.12235625881247061,\n",
       " 17.41: 0.1154629484568385,\n",
       " 17.75: 0.12611624627917908,\n",
       " 18.12: 0.13770954096819682,\n",
       " 18.15: 0.13864953783487385,\n",
       " 17.11: 0.10606297979006736,\n",
       " 16.84: 0.09760300798997337,\n",
       " 16.55: 0.08851637161209466,\n",
       " 16.46: 0.08569638101206334,\n",
       " 16.76: 0.09509634967883447,\n",
       " 16.27: 0.07974306752310825,\n",
       " 16.45: 0.08538304872317092,\n",
       " 17.3: 0.11201629327902243,\n",
       " 18.02: 0.13457621807927306,\n",
       " 18.22: 0.14084286385712044,\n",
       " 18.2: 0.14021619927933573,\n",
       " 18.08: 0.13645621181262726,\n",
       " 18.18: 0.139589534701551,\n",
       " 17.98: 0.13332288892370361,\n",
       " 18.27: 0.14240952530158232,\n",
       " 19.09: 0.1681027729907567,\n",
       " 18.63: 0.15368948770170765,\n",
       " 18.34: 0.14460285132382894,\n",
       " 18.31: 0.1436628544571518,\n",
       " 18.25: 0.14178286072379762,\n",
       " 18.195: 0.14005953313488959,\n",
       " 18.16: 0.13896287012376626,\n",
       " 18.37: 0.14554284819050609,\n",
       " 18.36: 0.14522951590161365,\n",
       " 16.97: 0.10167632774557415,\n",
       " 16.43: 0.0847563841453862,\n",
       " 15.8: 0.06501644994516688,\n",
       " 15.76: 0.06376312078959738,\n",
       " 14.63: 0.028356572144759555,\n",
       " 14.56: 0.026163246122512952,\n",
       " 14.41: 0.021463261789127386,\n",
       " 14.51: 0.02459658467805108,\n",
       " 14.44: 0.022403258655804476,\n",
       " 14.27: 0.017076609744634184,\n",
       " 14.12: 0.012376625411248615,\n",
       " 14.22: 0.015509948300172363,\n",
       " 14.26: 0.01676327745574182,\n",
       " 14.2: 0.014883283722387581,\n",
       " 14.25: 0.016449945166849455,\n",
       " 14.3: 0.01801660661131133,\n",
       " 14.58: 0.02678991070029768,\n",
       " 14.65: 0.02898323672254428,\n",
       " 14.91: 0.037129876233745904,\n",
       " 14.9: 0.03681654394485354,\n",
       " 14.7: 0.0305498981670061,\n",
       " 14.8: 0.03368322105592985,\n",
       " 14.75: 0.032116559611467976,\n",
       " 15.03: 0.040889863700454325,\n",
       " 14.73: 0.03148989503368325,\n",
       " 14.32: 0.018643271189096058,\n",
       " 14.5: 0.024283252389158714,\n",
       " 14.82: 0.03430988563371457,\n",
       " 15.04: 0.041203195989346686,\n",
       " 14.85: 0.03524988250039167,\n",
       " 15.15: 0.0446498511671628,\n",
       " 15.1: 0.04308318972270093,\n",
       " 14.94: 0.03806987310042299,\n",
       " 15.08: 0.0424565251449162,\n",
       " 15.16: 0.04496318345605516,\n",
       " 15.5: 0.05561648127839575,\n",
       " 15.68: 0.06125646247845841,\n",
       " 15.72: 0.06250979163402792,\n",
       " 15.585: 0.05827980573398093,\n",
       " 15.74: 0.06313645621181264,\n",
       " 15.85: 0.0665831113896287,\n",
       " 15.9: 0.06814977283409057,\n",
       " 16.3: 0.0806830643897854,\n",
       " 16.36: 0.08256305812313959,\n",
       " 16.32: 0.08130972896757013,\n",
       " 15.51: 0.055929813567288114,\n",
       " 16.26: 0.07942973523421595,\n",
       " 18.045: 0.13535954880150405,\n",
       " 17.99: 0.1336362212125959,\n",
       " 17.44: 0.11640294532351564,\n",
       " 17.1: 0.10574964750117505,\n",
       " 16.91: 0.09979633401221998,\n",
       " 16.41: 0.08412971956760146,\n",
       " 16.53: 0.08788970703430994,\n",
       " 16.79: 0.0960363465455115,\n",
       " 16.59: 0.08976970076766412,\n",
       " 16.33: 0.08162306125646245,\n",
       " 16.83: 0.09728967570108096,\n",
       " 16.86: 0.09822967256775811,\n",
       " 16.96: 0.10136299545668186,\n",
       " 17.17: 0.10794297352342165,\n",
       " 17.32: 0.11264295785680717,\n",
       " 17.19: 0.10856963810120639,\n",
       " 16.21: 0.07786307378975407,\n",
       " 16.22: 0.07817640607864638,\n",
       " 16.2914: 0.08041359862133793,\n",
       " 16.42: 0.08444305185649388,\n",
       " 16.16: 0.0762964123452922,\n",
       " 17.01: 0.10292965690114372,\n",
       " 17.87: 0.12987623374588755,\n",
       " 18.53: 0.150556164812784,\n",
       " 18.71: 0.15619614601284668,\n",
       " 18.89: 0.16183612721290933,\n",
       " 18.94: 0.1634027886573712,\n",
       " 19.3832: 0.17728967570108098,\n",
       " 18.1307: 0.13804480651731166,\n",
       " 17.86: 0.12956290145699514,\n",
       " 17.735: 0.1256462478458405,\n",
       " 18.13: 0.13802287325708912,\n",
       " 17.85: 0.12924956916810285,\n",
       " 18.03: 0.1348895503681655,\n",
       " 18.51: 0.1499295002349993,\n",
       " 18.59: 0.15243615854613818,\n",
       " 18.64: 0.15400281999060006,\n",
       " 18.5: 0.14961616794610685,\n",
       " 18.07: 0.13614287952373494,\n",
       " 17.91: 0.13112956290145703,\n",
       " 17.77: 0.12674291085696382,\n",
       " 17.26: 0.11076296412345299,\n",
       " 17.38: 0.11452295159016135,\n",
       " 17.261: 0.11079429735234216,\n",
       " 17.64: 0.12266959110136302,\n",
       " 17.07: 0.1048096506344979,\n",
       " 17.15: 0.10731630894563682,\n",
       " 17.49: 0.11796960676797741,\n",
       " 16.74: 0.09446968510104962,\n",
       " 16.28: 0.08005639981200068,\n",
       " 17.67: 0.12360958796804017,\n",
       " 17.81: 0.12799624001253326,\n",
       " 16.93: 0.10042299859000471,\n",
       " 19.645: 0.18549271502428324,\n",
       " 19.6: 0.18408271972426765,\n",
       " 23.34: 0.3012689957700141,\n",
       " 23.455: 0.3048723170922763,\n",
       " 22.82: 0.28497571674761085,\n",
       " 22.44: 0.27306908976970085,\n",
       " 22.9: 0.2874823750587498,\n",
       " 21.65: 0.2483158389472035,\n",
       " 21.11: 0.23139589534701552,\n",
       " 18.44: 0.14773617421275267,\n",
       " 18.28: 0.14272285759047476,\n",
       " 18.74: 0.1571361428795237,\n",
       " 18.06: 0.13582954723484253,\n",
       " 17.9: 0.1308162306125646,\n",
       " 17.52: 0.11890960363465455,\n",
       " 17.68: 0.12392292025693248,\n",
       " 17.92: 0.13144289519034943,\n",
       " 19.795: 0.1901926993576689,\n",
       " 19.4775: 0.18024439918533605,\n",
       " 19.35: 0.17624941250195839,\n",
       " 18.38: 0.14585618047939838,\n",
       " 18.32: 0.1439761867460442,\n",
       " 18.3: 0.14334952216825947,\n",
       " 18.65: 0.15431615227949239,\n",
       " 18.52: 0.1502428325238916,\n",
       " 18.76: 0.15776280745730853,\n",
       " 18.92: 0.16277612407958647,\n",
       " 19.9: 0.19348268839103866,\n",
       " 20.29: 0.20570264765784113,\n",
       " 19.01: 0.1655961146796178,\n",
       " 19.1138: 0.1688485038383206,\n",
       " 18.56: 0.15149616167946103,\n",
       " 17.971: 0.13304088986370047,\n",
       " 17.935: 0.13191289362368788,\n",
       " 18.14: 0.13833620554598156,\n",
       " 17.36: 0.11389628701237663,\n",
       " 16.2: 0.07754974150086165,\n",
       " 16.4: 0.08381638727870903,\n",
       " 15.88: 0.06752310825630585,\n",
       " 15.69: 0.06156979476735077,\n",
       " 18.164: 0.13908820303932326,\n",
       " 18.17: 0.1392762024126587,\n",
       " 17.76: 0.1264295785680715,\n",
       " 18.45: 0.148049506501645,\n",
       " 18.05: 0.13551621494595023,\n",
       " 17.910999999999998: 0.13116089613034618,\n",
       " 17.24: 0.11013629954566814,\n",
       " 16.81: 0.09666301112329623,\n",
       " 16.9: 0.09948300172332755,\n",
       " 16.73: 0.09415635281215733,\n",
       " 15.46: 0.054363152122826296,\n",
       " 16.045: 0.07269309102303,\n",
       " 16.17: 0.07660974463418461,\n",
       " 16.15: 0.07598308005639978,\n",
       " 15.4: 0.05248315838947206,\n",
       " 15.71: 0.062196459345135555,\n",
       " 14.505: 0.024439918533604926,\n",
       " 14.0: 0.008616637944540196,\n",
       " 14.59: 0.027103242989190042,\n",
       " 14.81: 0.03399655334482221,\n",
       " 15.18: 0.04558984803383989,\n",
       " 14.96: 0.03869653767820778,\n",
       " 14.8463: 0.03513394955350148,\n",
       " 14.62: 0.028043239855867135,\n",
       " 14.23: 0.01582328058906473,\n",
       " 14.19: 0.014569951433495218,\n",
       " 14.06: 0.010496631677894434,\n",
       " 13.725: 0.0,\n",
       " 14.3301: 0.018959736800877338,\n",
       " 14.16: 0.013629954566818127,\n",
       " 14.04: 0.009869967100109652,\n",
       " 14.05: 0.01018329938900207,\n",
       " 14.13: 0.012689957700141035,\n",
       " 14.15: 0.013316622277925762,\n",
       " 13.98: 0.007989973366755469,\n",
       " 14.08: 0.011123296255679161,\n",
       " 13.92: 0.006109979633401231,\n",
       " 13.9: 0.0054833150556165035,\n",
       " 14.17: 0.01394328685571049,\n",
       " 17.02: 0.10324298919003604,\n",
       " 16.68: 0.09258969136769545,\n",
       " 17.06: 0.1044963183456055,\n",
       " 17.31: 0.11232962556791475,\n",
       " 17.14: 0.1070029766567445,\n",
       " 16.85: 0.0979163402788658,\n",
       " 16.89: 0.09916966943443525,\n",
       " 15.83: 0.06595644681184397,\n",
       " 15.33: 0.05028983236722546,\n",
       " 15.565: 0.057653141156196144,\n",
       " 16.7: 0.09321635594548017,\n",
       " 16.62: 0.09070969763434127,\n",
       " 16.13: 0.07535641547861505,\n",
       " 16.38: 0.08318972270092431,\n",
       " 18.33: 0.1442895190349365,\n",
       " 18.77: 0.15807613974620086,\n",
       " 19.06: 0.16716277612407957,\n",
       " 18.48: 0.14898950336832215,\n",
       " 17.715: 0.1250195832680558,\n",
       " 17.59: 0.12110292965690116,\n",
       " 17.78: 0.12705624314585623,\n",
       " 17.4975: 0.11820460598464669,\n",
       " 14.53: 0.025223249255835807,\n",
       " 13.91: 0.005796647344508867,\n",
       " 14.52: 0.024909916966943443,\n",
       " 14.31: 0.018329938900203693,\n",
       " 15.62: 0.059376468745104174,\n",
       " 16.29: 0.08036973210089299,\n",
       " 15.55: 0.05718314272285763,\n",
       " 16.77: 0.09540968196772677,\n",
       " 15.48: 0.054989816700611024,\n",
       " 17.61: 0.12172959423468588,\n",
       " 18.47: 0.1486761710794297,\n",
       " 19.32: 0.17530941563528124,\n",
       " 20.198: 0.20281999060003136,\n",
       " 21.18: 0.2335892213692621,\n",
       " 21.85: 0.25458248472505096,\n",
       " 22.11: 0.26272912423625255,\n",
       " 22.15: 0.263982453391822,\n",
       " 22.21: 0.2658624471251763,\n",
       " 22.31: 0.2689957700140999,\n",
       " 22.5: 0.274949083503055,\n",
       " 22.55: 0.2765157449475169,\n",
       " 22.37: 0.2708757637474542,\n",
       " 22.09: 0.26210245965846785,\n",
       " 21.99: 0.2589691367695441,\n",
       " 22.66: 0.27996240012533297,\n",
       " 23.29: 0.29970233432555227,\n",
       " 23.8: 0.31568228105906315,\n",
       " 24.8: 0.3470155099483002,\n",
       " 24.34: 0.33260222465925116,\n",
       " 24.19: 0.3279022403258656,\n",
       " 23.54: 0.3075356415478615,\n",
       " 25.01: 0.35359548801504004,\n",
       " 24.91: 0.3504621651261163,\n",
       " 25.17: 0.3586088046373179,\n",
       " 25.0: 0.3532821557261476,\n",
       " 25.06: 0.3551621494595018,\n",
       " 25.67: 0.37427541908193646,\n",
       " 25.59: 0.37176876077079746,\n",
       " 25.02: 0.35390882030393234,\n",
       " 26.03: 0.3855553814820618,\n",
       " 25.93: 0.38242205859313805,\n",
       " 25.16: 0.3582954723484255,\n",
       " 24.9: 0.35014883283722387,\n",
       " 25.85: 0.3799154002819991,\n",
       " 26.37: 0.39620867930440234,\n",
       " 26.25: 0.3924486918376939,\n",
       " 26.68: 0.4059219802600658,\n",
       " 28.05: 0.4488485038383206,\n",
       " 28.45: 0.46138179539401536,\n",
       " 29.23: 0.4858217139276203,\n",
       " 29.04: 0.4798684004386652,\n",
       " 28.35: 0.4582484725050917,\n",
       " 27.76: 0.4397618674604419,\n",
       " 30.65: 0.5303148989503368,\n",
       " 30.48: 0.5249882500391666,\n",
       " 28.65: 0.4676484411718627,\n",
       " 30.57: 0.5278082406391978,\n",
       " 29.36: 0.48989503368322107,\n",
       " 28.38: 0.45918846937176877,\n",
       " 28.6: 0.466081779727401,\n",
       " 29.03: 0.4795550681497729,\n",
       " 28.01: 0.4475951746827511,\n",
       " 26.33: 0.3949553501488328,\n",
       " 24.65: 0.3423155256149146,\n",
       " 25.88: 0.38085539714867617,\n",
       " 24.915: 0.3506188312705624,\n",
       " 25.3979: 0.365749647501175,\n",
       " 26.575: 0.4026319912266959,\n",
       " 26.62: 0.40404198652671164,\n",
       " 27.1899: 0.42189879367068783,\n",
       " 26.99: 0.41563528121572924,\n",
       " 27.03: 0.4168886103712988,\n",
       " 27.0: 0.4159486135046217,\n",
       " 26.795: 0.40952530158232814,\n",
       " 27.17: 0.421275262415792,\n",
       " 26.95: 0.4143819520601598,\n",
       " 26.42: 0.3977753407488642}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalization (fname, attr, normType):\n",
    "    '''\n",
    "    Input Parameters:\n",
    "        fname: Name of the csv file contiaining historical quotes\n",
    "        attr: The attribute to be normalized \n",
    "        normType: The type of normalization \n",
    "    Output:\n",
    "        a dictionary where each key is the original column value and each value is the normalised column value. \n",
    "    '''\n",
    "    result = {\n",
    "        \n",
    "    }\n",
    "    \n",
    "    # your code here\n",
    "    df = pd.read_csv(fname)\n",
    "    \n",
    "    # Convert column index to name if attr is integer\n",
    "    if isinstance(attr, int):\n",
    "        attr = df.columns[attr]\n",
    "    \n",
    "    # Extract the column to normalize\n",
    "    column_data = df[attr]\n",
    "    \n",
    "    if normType == \"min_max\":\n",
    "        # Min-Max Normalization\n",
    "        normalized_data = (column_data - column_data.min()) / (column_data.max() - column_data.min())\n",
    "    elif normType == \"z_score\":\n",
    "        # Z-Score Normalization\n",
    "        normalized_data = (column_data - column_data.mean()) / column_data.std()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported normalization type: \" + normType)\n",
    "    \n",
    "    # Create a dictionary mapping original to normalized values\n",
    "    # Note: This approach may lead to loss of information if there are duplicate original values.\n",
    "    # To preserve all data, consider returning a list of tuples or using a different structure.\n",
    "    result = {original: normalized for original, normalized in zip(column_data, normalized_data)}\n",
    "    \n",
    "    return result\n",
    "\n",
    "normalization(\"./data/HistoricalQuotes.csv\", \"Low\", \"min_max\")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e0d7d290878957d9535e285ed9ba393",
     "grade": true,
     "grade_id": "test_normalization",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis cell has hidden test cases that will run after you submit your assignment. \\nYou can troubleshoot using the unit tests we shared below.\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This cell has hidden test cases that will run after you submit your assignment. \n",
    "You can troubleshoot using the unit tests we shared below.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T01:24:55.210777Z",
     "start_time": "2020-09-10T01:24:55.201476Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "862c679b0e1c220375a75868ae05a503",
     "grade": false,
     "grade_id": "correlation",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def correlation (fname1, attr1, fname2, attr2):\n",
    "    '''\n",
    "    Input Parameters:\n",
    "        fname1: name of the first csv file containing historical quotes\n",
    "        attr1: The attribute to consider in the first csv file (fname1)\n",
    "        fname2: name of the second csv file containing historical quotes\n",
    "        attr2: The attribute to consider in the second csv file (fname2)\n",
    "        \n",
    "    Output:\n",
    "        correlation coefficient between attr1 in fname1 and attr2 in fname2\n",
    "    '''\n",
    "    \n",
    "    correlation_coefficient = 0.0\n",
    "        \n",
    "    \n",
    "    #TODO: Write code given the Input / Output Paramters.\n",
    "    \n",
    "    # your code here\n",
    "    df1 = pd.read_csv(fname1)\n",
    "    df2 = pd.read_csv(fname2)\n",
    "    \n",
    "    # Ensure the column index is within bounds and convert to column name if necessary\n",
    "    if isinstance(attr1, int):\n",
    "        if attr1 < 0 or attr1 >= len(df1.columns):\n",
    "            raise ValueError(f\"Column index {attr1} out of bounds for file {fname1}\")\n",
    "        attr1 = df1.columns[attr1]\n",
    "    if isinstance(attr2, int):\n",
    "        if attr2 < 0 or attr2 >= len(df2.columns):\n",
    "            raise ValueError(f\"Column index {attr2} out of bounds for file {fname2}\")\n",
    "        attr2 = df2.columns[attr2]\n",
    "\n",
    "    # Check if the specified columns exist in the dataframes\n",
    "    if attr1 not in df1.columns:\n",
    "        raise ValueError(f\"Attribute {attr1} does not exist in file {fname1}\")\n",
    "    if attr2 not in df2.columns:\n",
    "        raise ValueError(f\"Attribute {attr2} does not exist in file {fname2}\")\n",
    "\n",
    "    # Extract the columns and calculate correlation\n",
    "    column1 = pd.to_numeric(df1[attr1], errors='coerce').dropna()\n",
    "    column2 = pd.to_numeric(df2[attr2], errors='coerce').dropna()\n",
    "    \n",
    "    correlation_coefficient = column1.corr(column2)\n",
    "    \n",
    "    return correlation_coefficient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f543a7eb3374de561e6640f3101fb49",
     "grade": true,
     "grade_id": "test_correlation",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis cell has hidden test cases that will run after you submit your assignment. \\nYou can troubleshoot using the unit tests we shared below.\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This cell has hidden test cases that will run after you submit your assignment. \n",
    "You can troubleshoot using the unit tests we shared below.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-10T01:28:36.101216Z",
     "start_time": "2020-09-10T01:28:36.049564Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e26989a1a0f566bbde748e091e86193c",
     "grade": false,
     "grade_id": "cell-073dcfbad9049939",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.026s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=3 errors=0 failures=0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestKnn(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.loc1 = \"data/test1.csv\"\n",
    "        self.loc2 = \"data/test2.csv\"\n",
    "        file = open('data/testing_normalization', 'rb')\n",
    "        self.data_normalization = pickle.load(file)\n",
    "        file.close()\n",
    "        file = open('data/testing_correlation', 'rb')\n",
    "        self.data_correlation = pickle.load(file)\n",
    "        file.close()\n",
    "        file = open('data/testing_zscore', 'rb')\n",
    "        self.zscore = pickle.load(file)\n",
    "        \n",
    "    def test0(self):\n",
    "        \"\"\"\n",
    "        Test min_max normalization \n",
    "        \"\"\"\n",
    "        result = normalization(\"./data/normalization_test_data.csv\", 0, \"min_max\")\n",
    "        for key,value in self.data_normalization.items():\n",
    "            self.assertAlmostEqual(result[key],value, places = 1)\n",
    "            \n",
    "    \n",
    "    def test1(self):\n",
    "        \"\"\"\n",
    "        Test zcore normalization\n",
    "        \"\"\"\n",
    "        result = normalization(\"./data/normalization_test_data.csv\", 1, \"z_score\")\n",
    "        for key, value in self.zscore.items():\n",
    "            self.assertAlmostEqual(result[key], value, places = 1)\n",
    "    \n",
    "    def test2(self):\n",
    "        \"\"\"\n",
    "        Test correlation \n",
    "        \"\"\"\n",
    "        result = correlation('./data/correlation_test_data.csv', 0, \"./data/correlation_test_data.csv\", 0)\n",
    "        self.assertAlmostEqual(result,self.data_correlation, places = 1)\n",
    "       \n",
    "   \n",
    "tests = TestKnn()\n",
    "tests_to_run = unittest.TestLoader().loadTestsFromModule(tests)\n",
    "unittest.TextTestRunner().run(tests_to_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "288051f75f190c1b29700f8c866f0c4a",
     "grade": false,
     "grade_id": "cell-1d57af814dafe68f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Problem 2\n",
    "***\n",
    "\n",
    "There are 4 functions that need to be completed:\n",
    "\n",
    "1. For each of the graphs, the input function parameters and the expected output has been mentioned below.\n",
    "2. Use the dataset provided in \"./data/HistoricalQuotes.csv\" to plot the below graphs.\n",
    "3. Instructions have been provided within each function regarding which attributes to choose from.\n",
    "4. The dataset has the following attributes\n",
    "    - Date\n",
    "    - Close\n",
    "    - Volume\n",
    "    - Open\n",
    "    - High\n",
    "    - Low\n",
    "\n",
    "Note:\n",
    "- Make sure the dataset you are using is the one mentioned in the problem statement.\n",
    "- After defining your functions. Create another block to call these functions by passing the attributes mentioned in canvas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aff2da14c79cd0b36f2d98169672690e",
     "grade": false,
     "grade_id": "cell-09f7dfae43c9f6f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# Plot size to 14\" x 7\"\n",
    "matplotlib.rc('figure', figsize = (14, 7))\n",
    "# Font size to 14\n",
    "matplotlib.rc('font', size = 14)\n",
    "# Do not display top and right frame lines\n",
    "matplotlib.rc('axes.spines', top = False, right = False)\n",
    "# Remove grid lines\n",
    "matplotlib.rc('axes', grid = False)\n",
    "# Set backgound color to white\n",
    "matplotlib.rc('axes', facecolor = 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8e320e21e3a51c6fc38e1065a5fce7b8",
     "grade": false,
     "grade_id": "cell-f262493a60cd8007",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def temporal_graph():\n",
    "    '''Input : x_data and y_data are the lists containing the data points for x and y axis\n",
    "    xlabel and ylabel are the labels that should be given to the corresponding axes\n",
    "    title contains the title of the graph\n",
    "    \n",
    "    Output : \n",
    "    Plot the temporal change of attributes High and Low values\n",
    "    Return a temporal graph with attributes Date on x-axis and a tuple of High and Low on y-axis displayed\n",
    "    \n",
    "    x_data - a python list of Dates using \"Date\" attribute from the dataset\n",
    "    y_data - a tuple of the High and Low values respectively. 'High' and 'Low' should be stored as python lists.\n",
    "             Ex: y_data = (list(df['attr_1']), list(df['attr_2']))\n",
    "    xlabel, ylabel - A string value representing the axes labels\n",
    "    title - A string representing the title for the graph\n",
    "    '''\n",
    "    \n",
    "    df = pd.read_csv('./data/HistoricalQuotes.csv')\n",
    "    \n",
    "    # your code here\n",
    "    x_data = list(df[\"Date\"])\n",
    "    y_data = (list(df['High']) , list(df['Low']))\n",
    "    xlabel = \"Date\"\n",
    "    ylabel = \"High - Low\"\n",
    "    title = \"temporal_graph\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    return x_data,y_data,xlabel,ylabel,title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10b78e6a952ddec151b6ef22c38ec8db",
     "grade": true,
     "grade_id": "cell-a8a9dace8000b375",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis cell has hidden test cases that will run after you submit your assignment. \\nYou can troubleshoot by calling the function and checking return types.\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This cell has hidden test cases that will run after you submit your assignment. \n",
    "You can troubleshoot by calling the function and checking return types.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef467c73f896a2883c3e1bc51d35c11f",
     "grade": false,
     "grade_id": "cell-51ff89ef927d6018",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def boxplot():\n",
    "    '''Input : x_data and y_data are the lists containing the data points for x and y axis\n",
    "    base_color and median_color can be used to set colors in the graph.\n",
    "    xlabel and ylabel are the labels that should be given to the corresponding axes\n",
    "    title contains the title of the graph.\n",
    "    \n",
    "    Output : A boxplot with Open and Close attributes on the x-axis displayed\n",
    "    \n",
    "    x_data - a tuple of Open and Close values respectively. Open and Close should be stored as a python list.\n",
    "             Ex: x_data = (list(df['attr_1']), list(df['attr_2']))\n",
    "    xlabel, ylabel - A string value representing the axes labels\n",
    "    title - A string representing the title for the graph\n",
    "    '''\n",
    "    \n",
    "    df = pd.read_csv('./data/HistoricalQuotes.csv')\n",
    "        \n",
    "    # your code here\n",
    "    x_data = (list(df['Open']) , list(df['Close']))\n",
    "    xlabel = \"Close\"\n",
    "    ylabel = \"Open\"\n",
    "    title = \"temporal_graph\"\n",
    "    \n",
    "    \n",
    "    return x_data,xlabel,ylabel,title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fdca2d2c76a46b748804df557feadf39",
     "grade": true,
     "grade_id": "cell-34f53d2a937e45f2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis cell has hidden test cases that will run after you submit your assignment. \\nYou can troubleshoot by calling the function and checking return types.\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This cell has hidden test cases that will run after you submit your assignment. \n",
    "You can troubleshoot by calling the function and checking return types.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6ab525c41e6e239d86036fcebe088341",
     "grade": false,
     "grade_id": "cell-6e477222af744e1e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def histogram():\n",
    "    '''Input : data is the list containing the data points for histogram buckets\n",
    "    xlabel and ylabel are the labels that should be given to the corresponding axes\n",
    "    title contains the title of the graph\n",
    "    \n",
    "    Output : A histogram of the Volume attribute displayed\n",
    "    \n",
    "    data - A python list containing the data associated with the Volume attribute\n",
    "    x_label, y_label - A string representing the axes labels \n",
    "    '''\n",
    "\n",
    "    df = pd.read_csv('./data/HistoricalQuotes.csv')\n",
    "\n",
    "    data = []\n",
    "    \n",
    "    # your code here\n",
    "    data = list(df.loc[:,\"Volume\"])\n",
    "    x_label = \"Volume\"\n",
    "    y_label = \"Volume\"\n",
    "        \n",
    "    \n",
    "    return data, x_label, y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a4c6c8e00948adc5769275f48e7bd2d3",
     "grade": true,
     "grade_id": "cell-9719ed64b0c27717",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis cell has hidden test cases that will run after you submit your assignment. \\nYou can troubleshoot by calling the function and checking return types.\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This cell has hidden test cases that will run after you submit your assignment. \n",
    "You can troubleshoot by calling the function and checking return types.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amzn_new_plot():\n",
    "    '''Define this function as you would seem fit to display the plot that interests you using\n",
    "    the same dataset. Define your function parameters and display the resulting plots'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
