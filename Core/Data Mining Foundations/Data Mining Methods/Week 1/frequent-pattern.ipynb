{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e413b24cf2f4ff97ee541826571fb8f",
     "grade": false,
     "grade_id": "cell-4e1696969eb81f75",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Homework 1 -  Frequent Pattern Analysis\n",
    "***\n",
    "**Name**: $<$insert name here$>$ \n",
    "***\n",
    "\n",
    "Remember that you are encouraged to discuss the problems with your instructors and classmates, but **you must write all code and solutions on your own**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "859fb2ffd4d82989d0cbc1fa55ab8970",
     "grade": false,
     "grade_id": "cell-a0424d7dd292f236",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The rules to be followed for the assignment are:\n",
    "\n",
    "- Do **NOT** load additional packages beyond what we've shared in the cells below.\n",
    "- Some problems with code may be autograded.  If we provide a function or class API **do not** change it.\n",
    "- Do not change the location of the data or data directory.  Use only relative paths to access the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f0fc7cdd13720bf65f2713d85f14294",
     "grade": false,
     "grade_id": "cell-208e6b52f66e263b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random \n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "550feb4db919af7af5bd76039b77502b",
     "grade": false,
     "grade_id": "cell-41899a355c39fa18",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### [10 points] Problem 1 - Apriori Implementation\n",
    "***\n",
    "\n",
    "A sample dataset has been provided to you in the './data/dataset.pickle' path. Here are the attributes for the dataset. Use this dataset to test your functions.\n",
    "\n",
    "- Dataset should load the transactions in the form of a python dictionary where each key holds the transaction id and the value is a python list of the items purchased in that transaction. \n",
    "- An example transaction will have the following structure. If items A, C, D, F are purchased in transaction T3, this would appear as follows in the dictionary.\n",
    "\n",
    "```python\n",
    "transactions = {\n",
    "   \"T3\": [\"A\", \"C\", \"D\", \"F\"]\n",
    "}\n",
    "```\n",
    "\n",
    "Note:\n",
    "- A sample dataset to test your code has been provided in the location \"./data/dataset.pickle\". Please maintain this as it would be necessary while grading.\n",
    "- Do not change the variable names of the returned values.\n",
    "- After calculating each of those values, assign them to the corresponding value that is being returned.\n",
    "\n",
    "- If you are encountering any errors while loading the dataset, the following lines of code should help. Please delete the cells before submitting, to reduce any potential autograder issues.\n",
    "\n",
    "```python\n",
    "!pip install pickle5\n",
    "\n",
    "import pickle5 as pickle\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "  \n",
    "def findsubsets(s, n):\n",
    "    \n",
    "#   A helper function that you can use to list of all subsets of size n. Do not make any changes to this code block.\n",
    "#   Input: \n",
    "#       1. s - A python list of items\n",
    "#       2. n - Size of each subset\n",
    "#   Output:\n",
    "#       1. subsets - A python list containing the subsets of size n.\n",
    "    \n",
    "    subsets = list(sorted((itertools.combinations(s,n))))\n",
    "    return subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def items_from_frequent_itemsets(frequent_itemset):\n",
    "\n",
    "#   A helper function that you can use to get the sorted items from the frequent itemsets. Do not make any changes\n",
    "#   to this code block\n",
    "#   Input:\n",
    "#       1. Frequent Itemsets\n",
    "#   Output:\n",
    "#       1. Sorted list of items\n",
    "\n",
    "    items = list()\n",
    "    for keys in frequent_itemset.keys():\n",
    "        for item in list(keys):\n",
    "            items.append(item)\n",
    "    return sorted(list(set(items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6c6a9b607de9874a42fa55da4dea5ed1",
     "grade": false,
     "grade_id": "cell-8aeecaf8c900b493",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_frequent_itemsets(dataset, support, items, n=1, frequent_items={}):\n",
    "    \n",
    "#   Input:\n",
    "#       1. dataset - A python dictionary containing the transactions.\n",
    "#       2. support - A floating point variable representing the min_support value for the set of transactions.\n",
    "#       3. items - A python list representing all the items that are part of all the transactions.\n",
    "#       4. n - An integer variable representing what frequent item pairs to generate.\n",
    "#       5. frequent_items - A dictionary representing k-1 frequent sets. \n",
    "#   Output:\n",
    "#       1. frequent_itemsets - A dictionary representing the frequent itemsets and their corresponding support counts.\n",
    "    \n",
    "    len_transactions = len(dataset)\n",
    "    if n == 1:\n",
    "        # your code here\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        \n",
    "        # your code here\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c8eab04a351ad1812a95cd02b5e4a19b",
     "grade": true,
     "grade_id": "cell-9189aa11b7c2f094",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# This cell has hidden test cases that will run after you submit your assignment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class TestX(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.min_support = 0.5\n",
    "        self.items = ['A', 'B', 'C', 'D', 'E']\n",
    "        self.dataset = dict()\n",
    "        self.dataset[\"T1\"] = ['A', 'B', 'D']\n",
    "        self.dataset[\"T2\"] = ['A', 'B', 'E']\n",
    "        self.dataset[\"T3\"] = ['B', 'C', 'D']\n",
    "        self.dataset[\"T4\"] = ['B', 'D', 'E']        \n",
    "        self.dataset[\"T5\"] = ['A', 'B', 'C', 'D']\n",
    "        \n",
    "    def test0(self):\n",
    "        frequent_1_itemsets = generate_frequent_itemsets(self.dataset, self.min_support, self.items)\n",
    "        print (frequent_1_itemsets)\n",
    "        frequent_1_itemsets_solution = dict()\n",
    "        frequent_1_itemsets_solution['A'] = 3\n",
    "        frequent_1_itemsets_solution['B'] = 5\n",
    "        frequent_1_itemsets_solution['D'] = 4\n",
    "\n",
    "        print (\"Test 1: frequent 1 itemsets\")\n",
    "        assert frequent_1_itemsets == frequent_1_itemsets_solution\n",
    "\n",
    "        frequent_2_itemsets = generate_frequent_itemsets(self.dataset, self.min_support, self.items, 2, frequent_1_itemsets)\n",
    "        print (frequent_2_itemsets)\n",
    "        frequent_2_itemsets_solution = dict()\n",
    "        frequent_2_itemsets_solution[('A', 'B')] = 3\n",
    "        frequent_2_itemsets_solution[('B', 'D')] = 4\n",
    "        \n",
    "        print (\"Test 1: frequent 2 itemsets\")\n",
    "        assert frequent_2_itemsets == frequent_2_itemsets_solution\n",
    "\n",
    "        frequent_3_itemsets = generate_frequent_itemsets(self.dataset, self.min_support, self.items, 3, frequent_2_itemsets)\n",
    "        print (frequent_3_itemsets)\n",
    "        frequent_3_itemsets_solution = dict()\n",
    "\n",
    "        print (\"Test 1: frequent 3 itemsets\")\n",
    "        assert frequent_3_itemsets == frequent_3_itemsets_solution         \n",
    "   \n",
    "tests = TestX()\n",
    "tests_to_run = unittest.TestLoader().loadTestsFromModule(tests)\n",
    "unittest.TextTestRunner().run(tests_to_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [10 points] Problem 2 - FP-Growth Implementation\n",
    "***\n",
    "\n",
    "A sample dataset has been provided to you in the './data/dataset.pickle' path. Here are the attributes for the dataset. Use this dataset to test your functions.\n",
    "\n",
    "- Dataset should load the transactions in the form of a python dictionary where each key holds the transaction id and the value is a python list of the items purchased in that transaction. \n",
    "- An example transaction will have the following structure. If items A, C, D, F are purchased in transaction T3, this would appear as follows in the dictionary.\n",
    "\n",
    "```python\n",
    "transactions = {\n",
    "   \"T3\": [\"A\", \"C\", \"D\", \"F\"]\n",
    "}\n",
    "```\n",
    "\n",
    "Note:\n",
    "- A sample dataset to test your code has been provided in the location \"./data/dataset.pickle\". Please maintain this as it would be necessary while grading.\n",
    "- Do not change the variable names of the returned values.\n",
    "- After calculating each of those values, assign them to the corresponding value that is being returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "79abe3e7a0526f6ba1ce2a16067ffc3d",
     "grade": false,
     "grade_id": "cell-044bd5cae7c41526",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def item_support(dataset, min_support):\n",
    "    \n",
    "#   A helper function that returns the support count of each item in the dataset. The dictionary is further sorted\n",
    "#   based on maximum support of each item and pruned based on min_support.\n",
    "#   Input:\n",
    "#       1. dataset - A python dictionary containing the transactions. \n",
    "#       2. items - A python list representing all the items that are part of all the transactions.\n",
    "#       3. min_support - A floating point variable representing the min_support value for the set of transactions.\n",
    "#   Output:\n",
    "#       1. support_dict - A dictionary representing the support count of each item in the dataset.\n",
    "    \n",
    "    len_transactions = len(dataset)\n",
    "    support_dict = dict()\n",
    "    for key, value in dataset.items():\n",
    "        \n",
    "        # your code here\n",
    "        \n",
    "                \n",
    "    sorted_support = dict(sorted(support_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "    pruned_support = {key:val for key, val in sorted_support.items() if val/len_transactions >= min_support}\n",
    "    \n",
    "    return support_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "01c2205b421f343b2900235853035d64",
     "grade": true,
     "grade_id": "cell-330eca95a174c213",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# This cell has hidden test cases that will run after you submit your assignment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9cff971bacb89c67cccfdf0e001244b",
     "grade": false,
     "grade_id": "cell-94f1180e7b0df5fe",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def reorder_transactions(dataset, min_support):\n",
    "    \n",
    "#   A helper function that reorders the transaction items based on maximum support count. It is important that you finish\n",
    "#   the code in the previous cells since this function makes use of the support count dictionary calculated above.\n",
    "#   Input:\n",
    "#       1. dataset - A python dictionary containing the transactions. \n",
    "#       2. items - A python list representing all the items that are part of all the transactions.\n",
    "#       3. min_support - A floating point variable representing the min_support value for the set of transactions.\n",
    "#   Output:\n",
    "#       1. updated_dataset - A dictionary representing the transaction items in sorted order of their support counts.\n",
    "\n",
    "    pruned_support = item_support(dataset, min_support) \n",
    "    updated_dataset = dict()\n",
    "    \n",
    "    # This loop sorts the transaction items based on the item support counts\n",
    "    for key, value in dataset.items():\n",
    "        updated_dataset[key] = sorted(value, key=pruned_support.get, reverse=True)\n",
    "    \n",
    "    # Update the following loop to remove items that do not belong to the pruned_support dictionary\n",
    "    for key, value in updated_dataset.items():\n",
    "        updated_values = list()\n",
    "        for item in value:\n",
    "            # your code here\n",
    "            \n",
    "        updated_dataset[key] = updated_values\n",
    "\n",
    "    return updated_dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5b17bc50d8a8f867ddb8b3d2aef80fee",
     "grade": true,
     "grade_id": "cell-f75886c98dbd692b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bcd039f72cfadd9a9875f3bf12015b66",
     "grade": false,
     "grade_id": "cell-d8903df190fbb499",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def build_fp_tree(updated_dataset):\n",
    "    \n",
    "#   Input: \n",
    "#       1. updated_dataset - A python dictionary containing the updated set of transactions based on the pruned support dictionary.\n",
    "#   Output:\n",
    "#       1. fp_tree - A dictionary representing the fp_tree. Each node should have a count and children attribute.\n",
    "#        \n",
    "#   HINT:\n",
    "#       1. Loop over each transaction in the dataset and make an update to the fp_tree dictionary. \n",
    "#       2. For each loop iteration store a pointer to the previously visited node and update it's children in the next pass.\n",
    "#       3. Update the root pointer when you start processing items in each transaction.\n",
    "#       4. Reset the root pointer for each transaction.\n",
    "#\n",
    "#   Sample Tree Output:\n",
    "#   {'Y': {'count': 3, 'children': {'V': {'count': 1, 'children': {}}}},\n",
    "#    'X': {'count': 2, 'children': {'R': {'count': 1, 'children': {'F': {'count': 1, 'children': {}}}}}}}\n",
    "    \n",
    "    fp_tree = dict()\n",
    "    for key, value in updated_dataset.items():\n",
    "        \n",
    "        # your code here\n",
    "        \n",
    "    return fp_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3487da265f4be3ad38b04e0a905b7da4",
     "grade": true,
     "grade_id": "cell-2e8a2c6ab7c275e5",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
